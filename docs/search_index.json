[["index.html", "Representing data Refresher Mathematics for Economics course Preface 0.1 How to read this book", " Representing data Refresher Mathematics for Economics course Economics Department, University of Warwick 2023-09-01 Preface This is a short e-book supporting the section on Data Appreciation of the Refresher Mathematics for Economics course at Warwick. The book uses a variety of data sources to provides examples of representing data. The exposition is structured around three topics Representing differences in living standards across countries and over time Representing data on climate change Representing income inequality Data is analyzed using R (R Core Team, 2023) - one of the most commonly used programming languages for statistical computing and graphics. The purpose of the book is three-fold. To enhance your understanding of what data is and of different types of data structures, by using real world examples. To provide examples of meaningful ways for representing data - summary statistics, two-way tables, graphs (histograms, bar charts, box plots, time-series line charts, etc) - in different contexts, using real-world data. To provide a brief introduction to R and some of its common packages. With reference to point 3. above, the book presents all R codes used together with the outputs from the code (such as graphs and tables). The codes are fully replicable - if you run all the blocks of code in your own R/RStudio installation (or on the cloud) in the order that they appear within each chapter, you will get identical results. This being said, a complete introduction to R is beyond the scope of this course and not all of the code will be explained in detail. You are nonetheless strongly encouraged to run the code yourself, and hopefully learn intuitively key aspects of the syntax of the language. Still, some parts of the document will include relatively advanced code, so do not worry if you do not understand everything (or even most of the code). 0.1 How to read this book We imagine that there could be two possible ways of reading the book, depending on whether you want to simply reflect on different ways of visualizing the data, or you also want to gain some understanding of coding in R. If you are not interested in using R to replicate the results yourself, then you can simply read through the e-book, reflect on the tables and figures presented, and their interpretation. This should be sufficient to gain some understanding of the variety of different types of tables and charts used to represent data. However, a more thorough way of engaging with the book and with data, is to additionally try to reflect on the codes producing the representations, ideally by replicating them in your own R/RStudio installation or on the cloud. As some understanding of coding is essential to economics, we would strongly recommend this approach. 0.1.1 How to run the codes yourself To run the codes and replicate the results yourself, you need to run R either on your own computer or on the cloud. We propose two different ways of doing this. First, if you would like to run the codes interactively (with the ability to make small changes in code and see how output is affected), but not install R on your machine yet, we have created a virtual online environment on mybinder.org where the codes from different chapters of the book can be run interactively. You can access the virtual environment here. This is perfectly sufficient for exploring all the codes related to the book and playing around by exploring how small changes in the code affect the output. Alternatively, you can install R and RStudio (both R and RStudio are free and open-source) on your own machine and replicate the codes in your own RStudio installation. The advantage of this approach, is that you will be able to use the software for subsequent work on data analysis - something that may be useful during your degree. Additionally, after the installation, running from your own installation will likely work faster than in the virtual environment on the cloud. If you are using a University computer, R and RStudio should already be installed. To install R and RStudio on your own personal computer, first download the most recent version of R for your operating system from CRAN and follow the instructions there to install. Next, download the most recent version of RStudio Desktop for your operating system from Posit website and follow the instructions there to install. Once you have your own installation, you will be able to copy chunks of code from the e-book into a script in your RStudio editor, and run from there. To make this easier, you can download all the data and Rscripts (containing all code) for the chapters from the book’s GitHub repository. Follow the instructions there to set up your local environment. References "],["some-basics.html", "Chapter 1 Some basics 1.1 Data 1.2 A note on R packages", " Chapter 1 Some basics This chapter discusses some essential concepts related to data and data analysis in R, and should be read prior to the subsequent chapters of the book. For ease of replication, all the data used in this chapter is available as an Excel file data_ch0.xlsx. To replicate the rest of the chapter in your own R installation, download the file and place it inside a folder on your computer. Then set the working directory in R to the folder where you placed the file. For me, this is the following folder: setwd(&quot;/home/emil/Desktop/book&quot;) In addition, run the following code to install all the R libraries that will be used for the analysis install.packages(&quot;readxl&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;ggplot2&quot;) install.packages(&quot;tidyr&quot;) and load them library(readxl) library(dplyr) library(ggplot2) library(tidyr) 1.1 Data While a precise definition of data is beyond the scope of this book, for practical purposes data can be understood as a structured collection of observations on a number of characteristics or variables. Data is typically organized into a structure in the form of a table (or matrix) with rows corresponding to distinct observations and columns corresponding to different variables. Data could be obtained in a variety of ways and from a variety of sources, and prior to analyzing data it is essential to understand the structure of the dataset obtained from a given source. While the rest of the book uses larger datasets, for clarity this chapter uses a mini-dataset obtained as a subsample of the data from the chapter (#ch1). This “mini-data” is stored in the Excel file data_ch0.xlsx under the sheet mini. First, load the data into R, allocating it to a dataframe called data, and print it as follows data &lt;- read_excel(&quot;data_ch0.xlsx&quot;, sheet=&quot;mini&quot;) data The “mini-dataset” includes information on region and GNI per capita in 2019, 2020 and 2021 for four countries. The data is structured in the form of a table with each row corresponding to an individual country. It includes the country’s region in the second column. Finally, the value of GNI per capita (PPP) for years 2019-2021 is represented in separate columns, labeled by the year. Note that there is some missing data (the GNP per capita of Turkmenistan in 2020 and 2021). 1.1.1 Cross-sectional, time-series, and panel data One important aspect of data structure is whether the data is cross-sectional, time-series, or panel. Cross-sectional data consists of observations on several subjects (such as individuals, firms, countries) at a single point or period of time. Time-series data consists of observations of a single subject over several points or periods of time. Panel (or longitudinal) data consists of observations on several subjects over several points or periods of time. It has both cross-sectional and time-series dimensions. The data loaded above is an example of panel data, as it includes observations on four cross-sectional units (countries) for three distinct periods of time (years). 1.1.1.1 Panel data - long and wide form When panel data is structured so that cross-sectional units vary across rows and time periods across columns (as above) it is said to be in wide form. While wide form is seemingly natural way to arrange data, for most computational purposes it is more appropriate to arrange panel data in long form - i.e., collapsing the time period so that a row of the data now corresponds to a pair of cross-sectional at a specific period of time: long.data &lt;- data %&gt;% pivot_longer( cols = `2019`:`2021`, names_to = &quot;Year&quot;, values_to = &quot;GNIpc&quot; ) long.data The same dataset in “long” form has 12 observations, with each observation (row) corresponding to a country in a given year. The dataset includes 4 variables (columns) identifying the country, its region, the year, and the country’s GNI per capita in the specific year. 1.1.1.2 Cross-sectional data An example of cross-sectional data, is the subset of the panel data above, at a particular year only. It has the following structure: cs.data &lt;- subset(long.data, Year==2021) cs.data In the context of our dataset, cross-sectional data is appropriate for understanding differences in living standards (measured by GNI per capita (PPP)) between countries (and between and within regions) at a specific point in time. 1.1.1.3 Time-series data An example of time-series data, is the subset of the panel data above, for a particular country only. It has the following structure: ts.data &lt;- subset(long.data, Country==&quot;UK&quot;) ts.data In the context of our dataset, time-series data is appropriate for understanding the dynamic evolution of living standards (measured by GNI per capita (PPP)) in a given country over time. As panel data has both cross-sectional and time-series dimensions, it is appropriate for analyzing both cross-country differences and dynamic evolution of living standards over time. 1.1.2 Visualizing the structure of your data As illustrated above, before starting any data analysis, it is essential to get a clear understanding of the structure of your data. For this reason, it is important to always inspect the data (i.e., the “table” or rows and columns), understanding what does an observation (row of data) identify, how are variables (columns of data) recorded, and so forth. In the rest of the book, whenever new dataset is loaded we will explicitly print the first few rows of the data to clarify the structure. In R, this can be easily done by using the function head() which will print the first few rows of the dataframe. The syntax is head(name_of_dataframe). While this is often sufficient for the purposes of the book, when you use more complicated datasets it is better to view the data in the data browser, using the function View() with syntax View(name_of_dataframe) which will return the whole “table” of data. 1.1.3 Categorical and quantitative variables Another important aspect of the data is the nature of the variables in it. A complete discussion of the types of variables and data types in R is beyond the scope of the document but a key distinction relevant for the subsequent analysis is between quantitative and qualitative (categorical) variables. To set ideas, consider the cross-sectional mini-dataset cs.data obtained above, consisting of 4 variables - Country, Region, Year and GNIpc. GNI per capita (measured in PPP adjusted international dollars) is clearly a quantitative variable. If we summarize the variable in R we can see that it has been correctly identified as quantitative summary(cs.data$GNIpc) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 2570 23680 44790 45423 66850 88910 1 as the summary() function reports a number of summary statistics of the distribution (e.g. mean, median, etc). Region is clearly a categorical variable, as there is no single natural order of its possible values. We can see that among the four countries in the mini-dataset, three are from Europe and Central Asia, and one from South Asia. However, if we summarize the variable in R summary(cs.data$Region) ## Length Class Mode ## 4 character character we see that it is classified as character (meaning text or string) which means that R does not recognize that three of the countries are from the same region. In such situations, it is important to explicitly tell R that the variable is categorical. In R, categorical variables are referred to as factor variables. We can declare the variable to be categorical as follows: cs.data$Region &lt;- as.factor(cs.data$Region) Now note that a summary of the variable summary(cs.data$Region) ## Europe and Central Asia South Asia ## 3 1 correctly recognises that the data consists of 3 countries from Europe and Central Asia and one country from South Asia. While this discussion is not necessarily crucial for understanding the data representations in the rest of the book, it is important for understanding some bits of code, as we will often have to declare the type of variables. 1.2 A note on R packages While a large number of functions are available as default in any R installation, one of the strengths of R, relative to other languages for statistical analysis, is that it has an extensive collection of user-contributed packages (collections of functions) which extend its functionality beyond the basis packages. In order to use such packages within your code you need to first install the relevant package by typing install.packages(\"name_of_package\") and then loading them inside your code by typing library(name_of_package). You will see that all chapters of the book use a variety of user-contributed packages which are installed and loaded in the beginning of the code. For example, at the beginning of this chapter we loaded four packages: readxl - which includes a number of functions for reading data from Excel files. One of the functions in the package is read_excel() which we used to read data from the Excel file. Since this is not a base function, the statement data &lt;- read_excel(\"data_ch0.xlsx\") would not have worked if we had not first installed and loaded the package. dplyr and tidyr - which include a large number of functions for reorganizing data. Without this the pivot_longer() function that we used to convert the panel dataset from wide to long format (this would have been possible with base R functions but much more cumbersome) ggplot2 - this is an excellent package for producing graphs. At this stage we have not yet used the package but it will be used extensively throughout the book. While a discussion of all the packages used is beyond the scope of the book, you can find all the key information related to them online. However, given the emphasis on producing graphs for the rest of the book, we will conclude this section with a brief discussion of the ggplot2 package (Wickham, 2016). To illustrate the use of ggplot() we load the second sheet from the data_ch0.xlsx file and allocate it to a dataframe csdata csdata &lt;- read_excel(&quot;data_ch0.xlsx&quot;, sheet=&quot;csdata&quot;) csdata Observe that the new dataset loaded is now a cross-section of observations for GNI per capita for 212 countries in 2019. We will say more about this data in the next chapter, but at this stage suppose that we want to produce a histogram summarizing the distribution of GNI per capita across countries in 2019. R has a base in-built function hist() for producing histograms which we can use to produce a histogram of the GNI per capita distribution in our data as follows: hist(csdata$GNIpc) While the R’s base in-built library for graphs graphics is sufficiently extensive (you can find more about it here), for the remainder of this book we will make use of the more advanced and customizable library ggplot2 (more here). To produce a histogram using ggplot2 ggplot(csdata, aes(x=GNIpc)) + geom_histogram() Before proceeding further let’s briefly discuss the philosophy of the ggplot syntax. - ggplot is called through the function ggplot() which takes as first argument the name of the dataframe used (and posibly specification of aesthetics - see below). - Then with + we add layers of types of graphs we want to plot. In the above example geom_histogram() specifies we are to plot a histogram. We could instead use geom_bar() for barcharts, geom_boxplot() for boxplots, and so forth. You will see many examples of layers in the book. - Either inside ggplot() or inside geom_...() we need to specify the variables based on which the graph is to be plotted. In ggplot this is specified via aesthetics through a function aes(). Loosely, this refers to a set of statements about what is being plotted - e.g., what goes on x and/or y axis, should different groups be plotted in different colors, etc. - Then all this can be customized further, by adding labels, color schemes, etc, as we will see throughout the book. For example, we can customize the histogram further, by changing the color and fill, adding labels and titles as below: ggplot(csdata, aes(x=GNIpc)) + geom_histogram(bins=60, color=&quot;black&quot;, fill=&quot;red&quot;, alpha=0.5)+ xlab(&quot;GNI per capita, PPP (2019)&quot;) + ylab(&quot;Number of countries&quot;) + labs(title=&quot;Histogram&quot;, subtitle=&quot;Distribution of real GNI per capita across countries, 2019&quot;) This all sounds quite complicated, but the philosophy of plotting will hopefully become increasingly clear through examples. References "],["ch1.html", "Chapter 2 Representing differences in living standards across countries and over time 2.1 Representing cross sectional data: Cross-country differences in living standards in 2019 2.2 Representing time-series data: Real GDP per capita in UK over time 2.3 Representing panel data: Cross-country differences in living standards over time - convergence and divergence", " Chapter 2 Representing differences in living standards across countries and over time Most of this chapter uses data on GNI per capita (PPP)1 from the World Bank’s World Development Indicators database (World Bank, 2023) available here. The chapter provides examples of using the data to represent differences in living standards between countries and over time. For ease of replication, all the data used in the chapter is available as an Excel file data_ch1.xlsx with different datasets saved as different tabs. To replicate the rest of the chapter, download the file and place it inside a folder on your computer. Then set the working directory in R to the folder where you placed the file. On my computer, this is done as follows: setwd(&quot;/home/emil/Desktop/book&quot;) In addition, run the following code to install all the R packages that will be used for the analysis: install.packages(&quot;readxl&quot;) install.packages(&quot;tidyr&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;ggplot2&quot;) install.packages(&quot;forcats&quot;) install.packages(&quot;stringr&quot;) install.packages(&quot;maps&quot;) install.packages(&quot;knitr&quot;) and load them library(readxl) library(tidyr) library(dplyr) library(ggplot2) library(forcats) library(stringr) library(maps) library(knitr) The complete dataset on GNI per capita (PPP) from WDI is available in the gnipcppp_long sheet of the data_ch1.xlsx Excel file. First, we load and inspect the the first few rows of the data # Load full panel dataset in long form longdata &lt;- read_excel(&quot;data_ch1.xlsx&quot;, sheet = &quot;gnipcppp_long&quot;) head(longdata) This is a panel dataset in long form, with each row identifying an individual country in a specific year. There are 10600 observations (country-year pairs) in total (212 countries followed over 50 years). In the remainder of this chapter, we will illustrate how individual cross sections, individual time series, or the whole panel dataset can be utilized to insightfully represent information from the data. The following code cleans the R environment so that the dataframes used in this section are no longer loaded: rm(list = ls()) 2.1 Representing cross sectional data: Cross-country differences in living standards in 2019 This section uses a cross section of the panel dataset for 2019 only, and presents examples of insightful ways of representing this data, with view of understanding differences in (distribution of) living standards as measured by GNI per capita (PPP), across countries in 2019. 2.1.1 Loading data First, to obtain cross-sectional data for 2019, we can load the full panel dataset in long form (found in the third sheet of the data_ch1.xlsx Excel file) and then only keep observations for 2019. # Load full panel dataset in long form longdata &lt;- read_excel(&quot;data_ch1.xlsx&quot;, sheet = &quot;gnipcppp_long&quot;) # Obtain a cross-section for Year 2019 only, and allocate to dataframe `csdata` csdata &lt;- subset(longdata, Year==2019) # Prepare by declaring `Country`, `Code` and `Region` to be factor (or categorical) variables csdata$Code &lt;- as.factor(csdata$Code) csdata$Region &lt;- as.factor(csdata$Region) csdata$Country &lt;- as.factor(csdata$Country) # Remove full panel dataset from memory rm(longdata) For completeness, the full cross sectional dataset we work with is presented in the following table csdata &lt;- csdata %&gt;% arrange(desc(rGNIpc)) csdata The dataset contains 212 observations (rows of data) on 5 variables (columns). An observation corresponds to an individual country. Variables are as follows: - Country is a categorical (factor) variable identifying the country. - Code is a categorical (factor) variable containing the country code - a standard 3-letter identifier of a country. It contains exactly the same information as Country, so adds nothing further to the information in the dataset. Nonetheless, in some representations below we will be interested in identifying individual countries in graphs, and the country code may be more compact label for the country than its name. - Region is a categorical (factor) variable, identifying a country’s region according to the World Bank’s standard classification of countries by regions. We will see more about that below. However, the presence of data on region adds a meaningful new dimension to the data as it allows us to represent not only features of the distribution of living standards across the world overall, but also between and within regions. - Year lists the year of observation. The variable is inherited from the original panel dataset. However, it equals 2019 for all observations in the cross section. Given the lack of variation, it contains no meaningful information for the purposes of the following representations (aside from the fact that we are looking at distributions in 2019 which we already know). - Finally, rGNIpc corresponds to GNI p.c. (PPP) - our main object of interest - and is a numeric variable. It is measured in 2022 international dollars - a counterfactual currency which is constructed as if 1 international dollar has the same purchasing power in each country (of course, imperfectly). 2.1.2 Summary of key variables To get a feel of the data, let’s summarize two of the key variables2: kable(summary(csdata$Region)) x East Asia and Pacific 34 Europe and Central Asia 57 Latin America and Caribbean 41 Middle East and North Africa 21 North America 3 South Asia 8 Sub-Saharan Africa 48 As we can see countries are categorized into 7 regions based on World Bank’s region classification. We can see that different regions include different numbers of countries. For example, there are only three countries in North America (by inspection Bermuda, Canada and the United States). Most countries (57) are in the region of Europe and Central Asia. summary(csdata$rGNIpc) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 230 2195 6435 15890 19693 117280 16 We can see that GNI per capita is unevenly distributed between countries, ranging from 230 international dollars per year to 117280 international dollars per year. The average GNI per capita in the sample - 15890 - is above the median - 6435. Data is not available for 16 countries. 2.1.3 Maps (for fun) Given that the unit of observation is a country, a (possibly) attractive way of visualizing cross-country differences, is through a map. The code below downloads an open-access geographic dataset of country coordinates which we can merge with our current data and produce a map. While the code is short , what happens under the hood is conceptually complex so we will make no attempt to explain the code. If you are interested in learning how to produce maps like this yourself, you can take a look at the discussion on the maps package website. # Load world map data from server world &lt;- map_data(&quot;world&quot;) # Merge world map data with GNI data gnimap.data &lt;- inner_join(world, csdata, by=c(&quot;region&quot;=&quot;Country&quot;)) # Set a simple map theme plainmap &lt;- theme( axis.text = element_blank(), axis.line = element_blank(), axis.ticks = element_blank(), panel.border = element_blank(), panel.grid = element_blank(), axis.title = element_blank(), panel.background = element_rect(fill = &quot;white&quot;), plot.title = element_text(hjust = 0.5) ) Once we have allocated the merged data into a new dataframe, gnimap.data, containing information on both geography and GNI per capita, we can plot a map as follows: ggplot(data = gnimap.data, mapping = aes(x = long, y = lat, group = group)) + coord_fixed(1.3) + geom_polygon(aes(fill = rGNIpc)) + scale_fill_distiller(palette =&quot;Blues&quot;, direction = -1, name=&quot;international $&quot;) + ggtitle(&quot;GNI per capita, PPP (2019)&quot;) + plainmap Notice that the colour (shade of blue) of each country corresponds to its GNI p.c. (PPP) as noted in the legend. While a map is an informative way to represent the geographic variation in GNI per capita, there are many aspects of the distribution which are not so easy to observe and would be better visualized later on. For the purposes of understanding our data, we next plot a map showing how the regions in our data (as categorised by the World Bank) are defined: ggplot(data = gnimap.data, mapping = aes(x = long, y = lat, group = group)) + coord_fixed(1.3) + geom_polygon(aes(fill = Region)) + ggtitle(&quot;Regions by World Bank classification&quot;) + plainmap This is all we are going to say about maps at this stage. Before proceeding further, we remove objects that will no longer be needed from the R environment: # Clean up rm(gnimap.data, plainmap, world,longdata) Also, for the purpose of some of the representations later it would be useful to remove observations with missing values of GNI pc from the dataset: csdata &lt;- subset(csdata, !is.na(rGNIpc)) Note that this leaves us with a sample of 196 countries from the initial 212. 2.1.4 Histograms A histogram of a random variable is a graph which divides the support of the variable, plotted on the horizontal axis, into a number of equally wide “bins”, with the height of each bin (on the vertical axis) equal to the number (or fraction) of observations falling into the bin. The histogram is a graphical representation of the distribution function of the variable. Using ggplot2, we can produce a histogram of the distribution of GNI per capita across countries as follows ggplot(csdata, aes(x=rGNIpc)) + geom_histogram(bins=60, color=&quot;black&quot;, fill=&quot;red&quot;, alpha=0.5)+ xlab(&quot;GNI per capita, PPP (2019)&quot;) + ylab(&quot;Number of countries&quot;) + labs(title=&quot;Histogram&quot;, subtitle=&quot;Distribution of real GNI per capita across countries, 2019&quot;) As can be seen from the histogram above, living standards (as measured by PPP-adjusted GNI per capita) are very unequally distributed across countries. The distribution of GNI p.c. is highly disperse (varying from close to 0 to about 115000 international dollars). In addition, it is strongly positively skewed (i.e., there are much more countries at the left tail of the distribution with few to the right forming a long right tail). Consistently with this positive skewness the mean GNI p.c. (at 15890) is well above the median (at 6435). 2.1.5 Quantiles While a histogram provides a rich description of the distribution of a continuous variable, other types of graphs and tables can visualize better other aspects of the differences between countries in the data. A way to get a quantitative feeling of the dispersion and asymmetry of the distribution is by calculating some of its quantiles: kable(quantile(csdata$rGNIpc,seq(0.1,0.9,0.1))) x 10% 910 20% 1880 30% 3270 40% 4490 50% 6435 60% 9510 70% 16355 80% 26960 90% 47355 We can see, for example, that - 10% of the countries in the dataset have GNI p.c. of no more than 910 international dollars; - 20% of the countries in the dataset have GNI p.c. of no more than 1880 international dollars; - 50% of the countries in the dataset have GNI p.c. of no more than 6435 international dollars (the median). By comparing different quantiles we can obtain a clear numerical sense of the differences between countries at different points of the distribution. 2.1.6 Quantile function While the above table only reports 9 quantiles, in principle we can provide a table of more (for example, 100 quantiles - or percentiles) but so much information would be cumbersome to read in a table. Instead, we may equivalently represent such information graphically. Given a random variable, e.g. GNI per capita (PPP) in 2019, its quantile function is defined as the mapping from \\(n\\in[0,1]\\) to the \\(n\\)-th quantile of its distribution. For example, if \\(q(n)\\) is the empirical quantile function for GNI per capita in our data, then given the observations of quantiles above, \\(q(0.1) = 910\\), \\(q(0.2)=1880\\) and \\(q(0.5)=6435\\). Hence, the way to represent graphically all quantiles of the distribution, is by a graph of its quantile function. One way to do this is as follows. First, create a new variable which records the quantile rank in the GNI p.c. distribution for each country (i.e., the quantile of GNI pc where each country is located) # Create a variable rGNIpc.rank representing the quantile rank of each country in the distribution of GNI p.c. csdata &lt;- csdata %&gt;% mutate(rGNIpc.rank = rank(rGNIpc)/length(rGNIpc)) # (Not essential) Sort country codes by GNI pc csdata$Code &lt;- fct_reorder(csdata$Code,csdata$rGNIpc) Next, plot quantile rank of each country against its corresponding GNI per capita (PPP) ggplot(csdata, aes(y=rGNIpc, x=rGNIpc.rank)) + geom_line() + xlab(&quot;Quantile rank&quot;) + ylab(&quot;International dollars&quot;) + labs(title=&quot;Empirical quantile function&quot;, subtitle = &quot;GNI per capita (PPP), 2019&quot;) While above we used geom_line() to fit a curve passing through the coordinates of each country. We can make this explicit by instead using points for each country. Doing so, and customizing the graph a bit further yields the following ggplot(csdata, aes(y=rGNIpc, x=rGNIpc.rank)) + geom_point(col=&quot;tomato&quot;) + geom_segment(aes(x=rGNIpc.rank, xend=rGNIpc.rank, y=0, yend=rGNIpc), col=&quot;tomato&quot;) + geom_text(aes(label=Code), check_overlap = TRUE, angle=90, hjust=-0.5, size=2) + xlab(&quot;Quantile rank&quot;) + ylab(&quot;International dollars&quot;) + labs(title=&quot;Empirical quantile function&quot;, subtitle = &quot;GNI per capita (PPP), 2019&quot;) Relative to a histogram, this representation draws more attention to “divergence” of living standards across countries (for example, we can easily see how rich are the richest relative to the poorest). For example, one interesting observation is as follows. Since countries are ordered by quantile rank (from poorest to richest) it is clear that the quantile function will be increasing. However, the empirical quantile function is not only increasing, but appears to exhibit approximately exponential pattern. To verify this, note that if we plotted the natural logarithm of GNI p.c. (rather than its level) on the vertical axis, we get “approximately” linear pattern: ggplot(csdata, aes(y=log(rGNIpc), x=rGNIpc.rank)) + geom_point(col=&quot;tomato&quot;) + geom_segment(aes(x=rGNIpc.rank, xend=rGNIpc.rank, y=4, yend=log(rGNIpc)), col=&quot;tomato&quot;) + geom_text(aes(label=Code), check_overlap = TRUE, angle=90, hjust=-0.5, size=2) + xlab(&quot;Quantile rank&quot;) + ylab(&quot;International dollars&quot;) + labs(title=&quot;Empirical quantile function&quot;, subtitle = &quot;GNI per capita (PPP), 2019&quot;) This tells us something fairly specific about the distribution (and in particular its skewness). If we order countries in ascending order of GNI p.c. (PPP), each subsequent country is richer than the previous one by approximately the same proportion (rather than for example, by the same number of international dollars). This is yet another manifestation of the skewness of the distribution, characterised by a long and thinning right tail. In order to get an idea of how the distribution varies between regions, we can make the colors elements different for different regions of the world: ggplot(csdata, aes(y=rGNIpc, x=rGNIpc.rank, col=Region)) + geom_point() + geom_segment(aes(x=rGNIpc.rank, xend=rGNIpc.rank, y=0, yend=rGNIpc)) + geom_text(aes(label=Code), check_overlap = TRUE, angle=90, hjust=-0.5, size=2) + xlab(&quot;Quantile rank&quot;) + ylab(&quot;International dollars&quot;) + labs(title=&quot;Empirical quantile function&quot;, subtitle = &quot;GNI per capita (PPP), 2019&quot;) + theme(legend.position = c(0.16, 0.7)) The graph shows clear regional differences. For example, there is a large concentration of countries from Sub-Saharan Africa at the lowest quantiles, and countries from North America and Europe and Central Asia in the highest quantiles. 2.1.7 Visualizing distribution within and between regions As already seen there seem to be systematic regional differences with respect to the distribution of GNI p.c. In what follows, we will look at ways to represent the data to understand these differences. To have a clearer point of reference, let’s first reorder the levels of the Region variable to be in ascending order of the median (per region): # Rearrange region in order of the median GNI pc. csdata$Region &lt;- fct_reorder(csdata$Region,csdata$rGNIpc, .fun = median) 2.1.7.1 Histograms by region Just like we can plot a histogram for the whole dataset, we can also plot separate histograms for regions: ggplot(csdata, aes(x=rGNIpc, fill=Region)) + geom_histogram(bins=10,color=&quot;black&quot;, alpha=0.9)+ labs(title=&quot;Histograms&quot;, subtitle=&quot;Distribution of GNI per capita within regions, 2019&quot;) + xlab(&quot;GNI per capita, PPP (2019)&quot;) + ylab(&quot;Number of countries&quot;) + facet_wrap(Region~., scales=&quot;free_y&quot;, strip.position = &quot;bottom&quot;)+theme(legend.position = &quot;none&quot;) Note that all histograms have the same horizontal axis, but different scales on the vertical axes. A few things coming out of the graph: - Countries in Sub-Saharan Africa and South Asia tend to have low GNI p.c. relative to other regions. - The three countries in North America - Bermuda, Canada and US have high GNI p.c. - There is quite a bit of dispersion across all regions. 2.1.7.2 Dot plots by region Given the relatively small number of observations, an alternative way to represent the same information is through dot plots. Suppose that we measure GNI p.c. on the horizontal axis, draw a separate vertical intercept for each region and plot each country as a point: ggplot(csdata, aes(x=Region, y=rGNIpc)) + geom_point(aes(col=Region), show.legend=F) + labs(title=&quot;Dot plot&quot;, subtitle=&quot;GNI per capita grouped by regions, 2019&quot;) + ylab(&quot;International $&quot;) + xlab(&quot;&quot;) + coord_flip() Unlike the histogram, we are not able to clearly see the density of the distribution for different ranges of GNI p.c. (as ranges with many countries contain too many points to differentiate between). For example, while we have 48 countries in Sub-Saharan Africa, most of them are far in the left tail of the distribution, and from the graph it appears as if there are fewer countries. Typically, this type of graph is more useful when we have a small number of observations. Nonetheless, it is still somewhat insightful in the context of our data with 196 observations. One advantage is that GNI p.c. is a continuous variable, and small variations are visible on the dot plot, but not on the histogram (which approximates the continuous distribution through a discrete one). 2.1.7.3 Summary statistics by region While histograms and dot plots provide rich representation of the distributions of GNI p.c. within and between regions, they contain too much information, which makes it difficult to gain a more quantitative feel of the regional differences (for example, it is not always easy to compare distributions between regions - given the histogram above are countries in Sub-Saharan Africa typically poorer or richer than in South Asia?). We can gain more quantitative feeling of regional differences by using summary statistics (numbers that summarize key aspects of the distributions such as central tendency and spread) by region. For example, we can obtain the median and mean (measures of central tendency) and standard deviation (measuring the “spread”) of the distributions of GNI p.c. for the different regions (i.e., conditional on region): csdata %&gt;% group_by(Region) %&gt;% summarize(median=median(rGNIpc), mean=mean(rGNIpc), sd=sd(rGNIpc)) The numbers should be fairly self-explanatory but in any case we can see that there are large differences in living standards across regions. In addition, we can see that distributions are more disperse the richer the region on average. 2.1.7.4 Bar charts by region One way to graphically represent key summary statistics (such as the information from the above table) is through bar charts. For example, a bar chart representing the median GNI p.c. by regions can be obtained as follows: ggplot(csdata, aes(y=rGNIpc, x=Region)) + geom_bar(stat=&#39;summary&#39;, fun=&#39;median&#39;, aes(fill=Region), show.legend=F) + labs(title=&quot;Bar chart&quot;,subtitle=&quot;Median GNI per capita (PPP), 2019&quot;) + xlab(&quot;&quot;) + ylab(&quot;International $&quot;) + coord_flip() We can produce similar bar charts for the other summary statistics. 2.1.7.5 Box plots by region A somewhat richer representation of regional differences, based on summary statistics, can be obtained by using box and whisker plots (also called simply box plots). A box plot of GNI p.c. by regions in our data can be obtained as follows: ggplot(csdata, aes(x=Region, y=rGNIpc)) + geom_boxplot(aes(fill=Region), show.legend=F) + labs(title=&quot;Box plot&quot;, subtitle=&quot;GNI per capita (PPP), 2019&quot;) + xlab(&quot;Region&quot;) + ylab(&quot;International $&quot;) + coord_flip() The vertical segments in the middle of the “boxes” correspond to the medians of the distributions by region. The boxes span the support from the 25th percentile to the 75th percentile (so 50% of the observations per region lie inside the corresponding box). The horizontal segments around the sides of the boxes are meant to represent parts of the support where observations are relatively common (precise statement of what this means is beyond the scope of the discussion here). The points, represent individual observations (countries) which have “unusually” extreme values (outliers). Unlike the bar chart, the box plot allows us to understand not only the central tendency of the conditional-on-region distributions, but also the dispersion, and skewness. 2.1.7.6 Categorizing countries by quintiles Another meaningful set of representations can be obtained by categorizing countries into groups according to their ranking in the distribution of GNI p.c. While this certainly leads to some loss of information, it may still be appropriate for representing features of the data that are difficult to achieve with continuous variables, as discussed below. First, let’s create a new variable qrank.rGNIpc which assigns countries into a quintile of the global GNI p.c. distribution: csdata &lt;- csdata %&gt;% arrange(rGNIpc) csdata &lt;- csdata %&gt;% mutate(qrank.rGNIpc=ntile(rGNIpc,5)) csdata$qrank.rGNIpc &lt;- as.factor(csdata$qrank.rGNIpc) levels(csdata$qrank.rGNIpc) = c(&quot;0-20%&quot;, &quot;20-40%&quot;, &quot;40-60%&quot;, &quot;60-80%&quot;, &quot;80-100%&quot;) Now we can characterize the joint distribution of region and GNI p.c. quintile in the form of a two-way table of counts: tab &lt;- table(csdata$Region, csdata$qrank.rGNIpc) kable(tab) 0-20% 20-40% 40-60% 60-80% 80-100% Sub-Saharan Africa 30 9 5 2 0 South Asia 3 4 0 1 0 East Asia and Pacific 2 12 4 4 6 Middle East and North Africa 1 8 2 4 5 Latin America and Caribbean 2 3 15 14 4 Europe and Central Asia 2 3 13 14 21 North America 0 0 0 0 3 To understand the meaning of the numbers, a few examples follow 30 of the countries in our data are in Sub-Saharan Africa and in the bottom quintile of the global GNI p.c. distribution. 4 of the countries in the data are in East Asia and Pacific region and are in the third quintile of the global GNI p.c. distribution. The same information can be represented in terms of proportions: kable(prop.table(tab), digits=2) 0-20% 20-40% 40-60% 60-80% 80-100% Sub-Saharan Africa 0.15 0.05 0.03 0.01 0.00 South Asia 0.02 0.02 0.00 0.01 0.00 East Asia and Pacific 0.01 0.06 0.02 0.02 0.03 Middle East and North Africa 0.01 0.04 0.01 0.02 0.03 Latin America and Caribbean 0.01 0.02 0.08 0.07 0.02 Europe and Central Asia 0.01 0.02 0.07 0.07 0.11 North America 0.00 0.00 0.00 0.00 0.02 So, for example, 15% of the countries in our data are in Sub-Saharan Africa and in the bottom quintile of the global GNI p.c. distribution. 2% of the countries in the data are in East Asia and Pacific region and are in the third quintile of the global GNI p.c. distribution. If we normalize the values in the table so that rows sum to 1, we get a table on the distribution of GNI p.c. quintiles conditional on regions: kable(prop.table(tab,1), digits=2) 0-20% 20-40% 40-60% 60-80% 80-100% Sub-Saharan Africa 0.65 0.20 0.11 0.04 0.00 South Asia 0.38 0.50 0.00 0.12 0.00 East Asia and Pacific 0.07 0.43 0.14 0.14 0.21 Middle East and North Africa 0.05 0.40 0.10 0.20 0.25 Latin America and Caribbean 0.05 0.08 0.39 0.37 0.11 Europe and Central Asia 0.04 0.06 0.25 0.26 0.40 North America 0.00 0.00 0.00 0.00 1.00 So for example, 65% of countries in Sub-Saharan Africa are in the bottom fifth of the global GNI p.c. distribution; additional 20% are in the second quintile, etc. On the other hand, 100% of countries in North America region are in the top fifth of the global GNI p.c. distribution. If instead we normalize the values in the table so that columns sum to 1, we get a table on the distribution of regions conditional on quintile of GNI p.c.: kable(prop.table(tab,2)) 0-20% 20-40% 40-60% 60-80% 80-100% Sub-Saharan Africa 0.750 0.2307692 0.1282051 0.0512821 0.0000000 South Asia 0.075 0.1025641 0.0000000 0.0256410 0.0000000 East Asia and Pacific 0.050 0.3076923 0.1025641 0.1025641 0.1538462 Middle East and North Africa 0.025 0.2051282 0.0512821 0.1025641 0.1282051 Latin America and Caribbean 0.050 0.0769231 0.3846154 0.3589744 0.1025641 Europe and Central Asia 0.050 0.0769231 0.3333333 0.3589744 0.5384615 North America 0.000 0.0000000 0.0000000 0.0000000 0.0769231 So for example, 75% of world’s poorest countries (i.e., countries in the bottom 20 percent) are in Sub-Saharan Africa. On the other hand, 8% of the world’s richest countries (in terms of quintile of global distribution) are in North America. The information from the two-way tables can be equivalently represented in bar charts. For example, the distribution of GNI p.c. quintiles by region (i.e., conditional on regions) can be represented as follows: ggplot(csdata, aes(x=Region, fill=qrank.rGNIpc)) + geom_bar(position=&#39;dodge&#39;, color=&quot;black&quot;) + labs(title=&quot;Bar chart&quot;,subtitle=&quot;Distribution of countries across GNI quintiles by region, 2019&quot;) + xlab(&quot;GNI per capita (PPP) Quintile&quot;) + ylab(&quot;Number of countries&quot;) The distribution of regions across GNI p.c. quintiles can be represented as follows: ggplot(csdata, aes(fill=Region, x=qrank.rGNIpc), na.rm = T) + geom_bar(position=&#39;dodge&#39;, color=&quot;black&quot;) + labs(title=&quot;Bar chart&quot;,subtitle=&quot;Distribution of countries across regions by GNI quintile, 2019&quot;) + xlab(&quot;GNI per capita (PPP) Quintile&quot;) + ylab(&quot;Number of countries&quot;) Following this let’s clean the R environment rm(csdata, tab) 2.1.8 Representing relationships between continuous variables In the data we use so far the only continuous variable is GNI per capita (PPP). However, we typically work with richer datasets and are often interested in representing the relationship between several continuous variables. To provide some examples of this, we load the dataset from sheet sc2019_multi in the data_ch1.xlsx Excel file: csdata.all &lt;- read_excel(&quot;data_ch1.xlsx&quot;, sheet=&quot;cs2019_multi&quot;) head(csdata.all) The new dataframe contains the same cross section of countries in 2019, but in addition to GNI per capita (PPP), includes two additional variables from the World Bank’s WMD database for 2019: LifeExpectancy: the average life expectancy at birth for each country CO2pc: the CO2 emissions per capita for each country. 2.1.8.1 GNI per capita and Life Expenctancy Let’s start by investigating how GNI per capita associates with life expectancy. A convenient way for representing the relationship between two continuous variables is through a scatterplot. In this case this can be a graph with GNI p.c. on the horizontal axis and life expectancy on the vertical axis, with each country’s combination of the two variables plotted by a point at the corresponding coordinates: ggplot(csdata.all,aes(x=rGNIpc, y=LifeExpectancy)) + geom_point() As we can see, there is a clear positive relationship between GNI per capita and life expectancy. Given the scale of measurement on both axes, the relationship appears to be non-linear. In such cases it is worth checking how changes in the scale of measurement affect the shape of the relationship. To explore this, let’s plot the natural log of GNI per capita (PPP) against the natural log of life expectancy: ggplot(csdata.all,aes(x=log(rGNIpc), y=log(LifeExpectancy))) + geom_point() As we can see, on logarithmic scales, the relationship appears approximately linear. This indicates that proportional increases in GNI per capita associate with proportional increases in life expectancy. Using the usual syntax we can customize the graph further: ggplot(csdata.all,aes(x=log(rGNIpc), y=log(LifeExpectancy))) + geom_point(col=&quot;red&quot;) + xlab(&quot;log(GNI per capita, PPP)&quot;) + ylab(&quot;log(Life Expectancy)&quot;) + labs(title=&quot;Scatterplot&quot;, subtitle=&quot;GNI per capita and life expecancy, 2019&quot;) Alternatively, rather than plotting points at the corresponding coordinates, we can instead plot as text the name of the country: ggplot(csdata.all,aes(x=log(rGNIpc), y=log(LifeExpectancy),label=Country)) + geom_text(col=&quot;red&quot;, check_overlap=TRUE, size=3) + xlab(&quot;log(GNI per capita, PPP)&quot;) + ylab(&quot;log(Life Expectancy)&quot;) + labs(title=&quot;Scatterplot&quot;, subtitle=&quot;GNI per capita and life expecancy, 2019&quot;) We can quantify the association by calculating the correlation coefficients between the two pairs of variables in natural units of measurement cor(csdata.all$rGNIpc, csdata.all$LifeExpectancy,use=&quot;complete.obs&quot;) ## [1] 0.6589774 in logs cor(log(csdata.all$rGNIpc), log(csdata.all$LifeExpectancy),use=&quot;complete.obs&quot;) ## [1] 0.8306506 In both cases we have high correlations, but especially in terms of log-levels. In summary, we observe that countries with higher GNI per capita tend to also have higher life expectancy. It should be noted, however, that association does not imply causal links. Based on what we observe, we are not able to conclude if higher GNI per capita causes higher life expectancy, or high life expectancy causes high GNI per capita, or if something else varies systematically over countries causing some to have high income and high life expectancy, while others to have low income and low life expectancy. 2.1.8.2 GNI per capita and CO2 emissions per capita In a similar way we can visualize the association between GNI per capita (PPP) and CO2 emissions per capita: ggplot(csdata.all,aes(x=log(rGNIpc), y=log(CO2pc), label=Country)) + geom_point(col=&quot;tomato2&quot;) + xlab(&quot;log(GNI per capita)&quot;) + ylab(&quot;log(CO2 emissions per capita)&quot;) + labs(title=&quot;Scatterplot&quot;, subtitle=&quot;GNI per capita and CO2 emissions&quot;) cor(log(csdata.all$rGNIpc), log(csdata.all$CO2pc),use=&quot;complete.obs&quot;) ## [1] 0.8721165 The association between the two seems to be even more pronounced. Again we can conclude that countries with high GNI per capita (PPP) tend to also have high CO2 emissions per capita. This completes the discussion of cross-sectional data. Next we will turn attention to visualizing time series. Before that let’s clean the R environment rm(csdata.all) 2.2 Representing time-series data: Real GDP per capita in UK over time This section provides examples of representing time-series data. Up until now we have used data on GNI per capita (PPP) from the World Bank’s World Development Indicators database. The cross-sectional dataset for 2019 that was used in the previous section, was obtained as from the full panel dataset by only keeping observations for 2019. Similarly, one way in which we can obtain a time-series dataset, is as a subset of the full panel dataset for an individual country only. While this is certainly feasible (and all the below codes can be replicated by using such a dataset) we will choose to use a slightly different dataset instead - namely, a quarterly time-series of UK’s real GDP per capita (rather than annual GNI per capita (PPP)) obtained from the Office for National Statistics here. We do so for several reasons: Atlas-method PPP-adjusted gross national income per capita is best-suited for comparing living standards between countries, but not so well-suited for understanding the dynamic change of real income within a country. Real GDP per capita is better suited for the latter. GNI per capita data from the World Bank’s WDI is only available annually. Data on real GDP per capita for UK is available at higher frequencies - in partiular, we will use quarterly data - which allows for better understanding of business cyclical fluctuations. The data from ONS has been saved in the uk_gdppc_qr sheet of the data_ch1.xlsx Excel file. Start by loading the data and printing the first few rows: ukgdp &lt;- read_excel(&quot;data_ch1.xlsx&quot;, sheet=&quot;uk_gdppc_qr&quot;) ukgdp$date &lt;- as.Date(ukgdp$date) head(ukgdp) The dataset includes quarterly observations on real GDP per capita from the begining of 1955 until the begining of 2023. There are only two variables: date which lists the quarter of the observation, and gdppc which gives the value of real GDP per capita measured in 2022 pounds. 2.2.1 Time-series line plots A common way to represent the behaviour of a time-series variable is through a time-series line plot. This is a graph that plots the value of the variable (in our case real GDP per capita) against time ggplot(ukgdp, aes(x=date, y=gdppc)) + geom_line() As usual the graph can be customized. The code below sets a different color and width of the line and adds labels and titles. ggplot(ukgdp, aes(x=date, y=gdppc)) + geom_line(col=&quot;red&quot;, size=1) + labs(title=&quot;Time-series line plot&quot;, subtitle = &quot;Real GDP per capita, quarterly, UK&quot;) + xlab(&quot;&quot;) + ylab(&quot;2022 £s&quot;) Over time real GDP per capita has exhibited an overall positive trend. In terms of 2022 GBP (henceforth £), UK’s average quarterly income has more than tripled from £2543 in the first quarter of 1955 to £8213 in the first quarter of 2023. We can also see that this overall growth has not been smooth - GDP fluctuates around trend over sequential periods of expansions and recessions - something known as the business cycle. For example, in the second quarter of 2020 (the through of the 2020 pandemic recession), per capita GDP fell to £6437 - a level last seen in 1998 - from a peak of £8386 two quarters ago. 2.2.2 Time-series line plots of the log transformation When representing the time path of a growing series over time it is often insightful to plot on a logarithmic scale (i.e., to plot the natural log of the series, rather than the series itself, against time). To see why this is the case, suppose that \\(Y_t\\) denotes GDP per capita, \\(Y\\), at quarter \\(t\\). When we plot \\(Y_t\\) against \\(t\\), the slope of the “curve” at any particular point is \\[\\frac{\\Delta Y_t}{\\Delta t}\\equiv\\frac{Y_{t+1}-Y_t}{(t+1)-t} = Y_{t+1}-Y_t = \\Delta Y_t\\] which is measured in the same units of measurement as the \\(Y_t\\) (i.e., pounds per quarter). Hence, if GDP were to grow at a constant positive growth rate over time, its time path would describe an increasing and convex schedule over time. Suppose that instead we plot the natural logarithm of GDP per capita against time. The slope of this curve at any particular point is instead \\[\\frac{\\Delta log(Y_t)}{\\Delta t}=log(Y_{t+1})-log(Y_t)=log\\left(\\frac{Y_{t+1}}{Y_t}\\right)=log\\left(1+\\frac{Y_{t+1}-Y_t}{Y_t}\\right)\\approx \\frac{Y_{t+1}-Y_t}{Y_t}\\] which equals the quarterly growth rate (percentage change quarter-on-quarter) of GDP. Hence, if GDP were to grow at a constant positive growth rate over time, the time path of its natural logarithm would describe a linear schedule over time. This allows us to quickly spot if there are systematic changes in growth rates over periods of time. For example, plotting the log of UK’s GDP per capita over time ggplot(ukgdp, aes(x=date, y=log(gdppc))) + geom_line(col=&quot;red&quot; ,size=1) + labs(title=&quot;Time-series line plot&quot;, subtitle = &quot;Real GDP per capita, quarterly, UK&quot;) + xlab(&quot;&quot;) + ylab(&quot;log(2022 £s)&quot;) We observe that the time path described by the log of real GDP per capita is “approximately” linear from 1955 to 2007, but afterwards shifts to a lower and flatter linear path. This indicates that real GDP growth rates were “approximately constant” from 1955 until the onset of the Great Recession in 2007, but afterwards average growth rates declined. This slowdown of GDP growth rates is one of the manifestations of a phenomenon known as UK’s productivity slowdown (although similar patterns have been observed in many other economies for the same time period). One naive but possibly insightful way to visualize this slowdown is to imagine that after 2007 GDP per capita experienced the same growth rate as it did in the prior decades, and to compare the actual series to a counterfactual series for real GDP per capita that would have prevailed under the previous growth rates. To do this first, find the counterfactual constant average quarterly growth rate from 1955 to 20073 avegr.preGR&lt;-(ukgdp$gdppc[ukgdp$date==&quot;2007-01-01&quot;]/ukgdp$gdppc[ukgdp$date==&quot;1955-01-01&quot;])^(1/((2007-1955)*4))-1 next, construct a new variable cfgdppc which equals to the actual value of GDP per capita in the first quarter of 1955, and then increases by the amount of the average growth rate identified above each subsequent quarter. One (inefficient but transparent) way to do this is using a loop: ukgdp$cfgdppc &lt;- ukgdp$gdppc[ukgdp$date==&quot;1955-01-01&quot;] for (i in 1:length(ukgdp$date)){ ukgdp$cfgdppc[i]=ukgdp$cfgdppc[1]*(1+avegr.preGR)^(i-1) } finally, plot both the actual and counterfactual GDP per capita series against time: ggplot(ukgdp) + geom_line(aes(x=date, y=gdppc, linetype=&quot;Actual&quot;), size=1, col=&quot;red&quot;) + geom_line(aes(x=date, y=cfgdppc, linetype=&quot;Pre-2007 trend&quot;), alpha=0.4, size=1, col=&quot;blue&quot;) + labs(title=&quot;Time-series line plot&quot;, subtitle = &quot;Real GDP per capita, quarterly, UK&quot;) + xlab(&quot;&quot;) + ylab(&quot;2022 £s&quot;) + labs(linetype=&quot;&quot;) or alternatively, the natural logs of the two series against time: ggplot(ukgdp) + geom_line(aes(x=date, y=log(gdppc), linetype=&quot;Actual&quot;),size=1, col=&quot;red&quot;) + geom_line(aes(x=date, y=log(cfgdppc), linetype=&quot;Pre-2007 trend&quot;), alpha=0.4, col=&quot;blue&quot;, size=1) + labs(title=&quot;Time-series line plot&quot;, subtitle = &quot;Real GDP per capita, quarterly, UK&quot;) + xlab(&quot;&quot;) + ylab(&quot;log(2022 £s)&quot;) + labs(linetype=&quot;&quot;) As we can see the actual series tracks closely the counterfactual one prior to 2007 (indicating approximately constant growth rates over the period) but then diverges sharply from it during the Great Recession and furthermore continues growing at a slower average rate than before. It should be noted that this exercise should be viewed with some skepticism (for a number of reasons but especially) due to the relatively naive way of fitting a trend. This being said there is no uncontroversial way of estimating trends. Furthermore, much more general and sophisticated empirical and theoretical approaches detect a systematic decline in productivity growth in the last decades. Understanding the reasons for the productivity growth decline is a hot topic of debate in economics, and you will learn about this during your studies, but further discussion is beyond the scope of this book. 2.2.3 Recessions As already discussed GDP per capita fluctuates systematically over the business cycle - in some periods it is above trend and in others below trend. In a general sense, periods of significant decline below trend are referred to as recessions. While precise technical definitions of a recession vary across countries, in the UK recessions are technically defined as a period of at least two consecutive quarters of negative GDP growth. When plotting macroeconomic time-series it is common to explicitly visualize periods defined as recessions, and we show how to do this here. First, the sheet recs of the data_ch1.xlsx Excel file contains data on all recessions in UK from 1955 to 2023 according to the technical definition. recs &lt;- read_excel(&quot;data_ch1.xlsx&quot;, sheet=&quot;recs&quot;) recs$rec_st &lt;- as.Date(recs$rec_st) recs$rec_en &lt;- as.Date(recs$rec_en) recs The two variables rec_st and rec_en list the starting and ending quarter of each of the recessions. Now, by plotting the real GDP per capita series, and adding colored rectangles between corresponding starting and ending dates of recessions we obtain the following plot: ggplot(ukgdp) + geom_line(aes(x=date, y=gdppc), col=&quot;red&quot;, size=1) + labs(title=&quot;Time-series line plot&quot;, subtitle = &quot;Real GDP per capita, quarterly, UK&quot;) + xlab(&quot;&quot;) + ylab(&quot;2022 £s&quot;) + geom_rect(data=recs,aes(xmin=rec_st, xmax=rec_en, ymin=-Inf, ymax=+Inf), fill=&#39;tomato&#39;, alpha=0.2) As we can see, there have been 8 recessions over the period. Two of the most notable ones are the two most recent - the Great Recession of 2007-2009 and the Covid-19 recession. We can also see that while the Covid-19 recession was associated with the largest quarterly decline in GDP per capita, it was also the shortest among all according to the technical definition. 2.2.4 Growth rates On many occasions one might be interested in analyzing the dynamic behaviour of the growth rate of GDP per capita, rather than its level. A common way to measure GDP growth rates with quarterly data is in terms of annual percentage changes relative to a year ago4. Let \\(Y_t\\) denote the value of GDP per capita in quarter \\(t\\). Then its annual growth rate relative to year (4 quarters) ago is defined as \\[\\frac{Y_t-Y_{t-4}}{Y_{t-4}} \\] We can create a new variable gdppc.gr based on the above: ukgdp &lt;- ukgdp %&gt;% mutate(gdppc.gr = (gdppc - lag(gdppc,4))/lag(gdppc,4)) Inspecting the data head(ukgdp) note that observations on the growth rate are missing in the first 4 quarters of the sample, as the levels from 4 quarters ago are not available. Plotting growth rates against time yields the following ggplot(ukgdp) + geom_line(aes(x=date, y=gdppc.gr), col=&quot;red&quot;) + labs(title=&quot;Time-series line plot&quot;, subtitle = &quot;Real GDP growth rate, quarterly, UK&quot;) + xlab(&quot;&quot;) + ylab(&quot;Percentage change on year ago&quot;) + geom_rect(data=recs,aes(xmin=rec_st, xmax=rec_en, ymin=-Inf, ymax=+Inf), fill=&#39;blue&#39;, alpha=0.2) While this plot is effectively based on the same information as as the plots of the level of GDP per capita above (in the sense that data on levels can be easily transformed into data on percentage changes and vice versa), given the scale of measurement it draws attention different aspects of the series. For example, now we can readily see that in the second quarter of the Covid-19 recession, quarterly GDP per capita had dropped by more than 20 percent relative to a year ago. The size of the quarterly fluctuations surrounding the Covid-19 recessions makes it somewhat difficult to visualize what is happening prior to it. If we replicate the same graph only until the last quarter of 2019 ggplot(subset(ukgdp,date&lt;&quot;2020-01-01&quot;)) + geom_line(aes(x=date, y=gdppc.gr), col=&quot;red&quot;) + labs(title=&quot;Time-series line plot&quot;, subtitle = &quot;Real GDP growth rate, quarterly, UK&quot;) + xlab(&quot;&quot;) + ylab(&quot;Percentage change on year ago&quot;) + geom_rect(data=recs[1:7,],aes(xmin=rec_st, xmax=rec_en, ymin=-Inf, ymax=+Inf), fill=&#39;blue&#39;, alpha=0.2) we can observe more clearly the dynamics of growth rates from 1955 to 2020. One thing that we can see (perhaps not very clearly) is that while there is no clear monotonic trend (as for GDP per capita in levels) typical growth rates after year 2000 tend to be lower than before - this is again the productivity slowdown discussed above. Another thing we can observe is that in some sense growth rates after the 1990s tend to exhibit smaller volatility relative to before. While the Great Recession is a notable exception, it can be noticed that even in periods of expansion, fluctuations were more volatile before some time in the 1990s. This empirical observation is often referred to as the Great Moderation (although, traditionally this term has been used to describe the period from 1990s to the Great Recession, but as we can see volatility has been relatively low in the next decade as well). 2.2.5 Distributions again While this may be obvious, it is worth noting that meaningful representations of time series do not need to involve plotting series over time. In fact, depending on the context any of the tools we have seen in representing cross-sectional data might be useful for illustrating relevant features of time series data. For example, it is clear that while we can plot a histogram of UK’s quarterly GDP per capita time series, this will be a meaningless (you can try yourself and reflect on what you see). However, a histogram of the GDP per capita growth rates time series is actually informative: ggplot(ukgdp, aes(x=gdppc.gr)) + geom_histogram(col=&quot;black&quot;, fill=&quot;red&quot;, binwidth=0.01)+ labs(title=&quot;Histogram&quot;, subtitle = &quot;Distribution of growth rates&quot;) + ylab(&quot;Number of quarters&quot;) + xlab(&quot;Percentage change on year ago&quot;) We can see that during the sample period, annual growth rates of around 1%-2% are most common, growth rates slightwly above or below this are relatively common, larger deviations are increasingly uncommon. It can also be noted that the two most extreme observations (which by inspection occur at the onset and recovery from the Covid-19 recession) appear as extreme outliers based on what one might have expected before. As another example, recall that we have already observed a slowdown of growth over time, as well as a decrease in volatility of fluctuations over time. One way to explore this in terms of summary statistics is by plotting box plots by decade. The code below creates a variable for decade and plots box plots for the decades from 1960s to 2010s (while we observe some data from 1950s and 2020s we have smaller number of observations than in the other decades so these are omitted) ukgdp$year &lt;- as.numeric(format(ukgdp$date, format=&quot;%Y&quot;)) ukgdp &lt;- ukgdp %&gt;% mutate(decade = floor(year / 10) * 10) ukgdp$decade &lt;- as.factor(ukgdp$decade) levels(ukgdp$decade) &lt;- c(&quot;1950s&quot;, &quot;1960s&quot;, &quot;1970s&quot;, &quot;1980s&quot;, &quot;1990s&quot;, &quot;2000s&quot;, &quot;2010s&quot;, &quot;2020s&quot;) ukgdp.trunc &lt;- subset(ukgdp,year&lt;2020&amp;year&gt;1959) ggplot(ukgdp.trunc, aes(x=decade)) + geom_boxplot(aes(y=gdppc.gr, col=decade)) + coord_flip() + geom_hline(aes(yintercept=mean(gdppc.gr, na.rm=TRUE), col=&quot;Average&quot;), linetype=&quot;dashed&quot;, size=1)+ labs(title=&quot;Box plot&quot;, subtitle = &quot;Distribution of growth rates by decade&quot;) + xlab(&quot;Decade&quot;) + ylab(&quot;Percentage change on year ago&quot;) + theme(legend.position=&quot;False&quot;) As we can see, indeed it appears that the distributions of growth rates have shifted leftwards over time (slowdown) and became increasingly less spread out (moderation). rm(ukgdp,ukgdp.decade, avegr.preGR, i, ukgdp.trunc, recs) 2.3 Representing panel data: Cross-country differences in living standards over time - convergence and divergence The last section of the chapter uses the full panel dataset to provide examples of representations that use both cross-sectional and time variation. First, load the full panel dataset in long form and prepare for analysis: longdata &lt;- read_excel(&quot;data_ch1.xlsx&quot;, sheet = &quot;gnipcppp_long&quot;) longdata$Code &lt;- as.factor(longdata$Code) longdata$Region &lt;- as.factor(longdata$Region) longdata$Country &lt;- as.factor(longdata$Country) The first few rows of data look as follows: head(longdata) An observation (a row of data) is now for country-year pairs. We have data on 212 countries for 50 years (1973-2022), so 10600 (=212x50) observations in total. At this stage it should be clear that panel data allows us to represent both cross-sectional variations across countries at a specific period of time (for example, from the full panel we can obtain a cross section at a specific year, as we did two sections ago) and time-series variations for a specific country (for example, by only keeping data for an individual country, resulting in a time-series data). However, in addition to simply converting our data to an individual cross-section or an individual time series, we can also represent patterns over both countries and time, which we can’t do in a simple cross-section or time-series. For example, we can (informally) treat the panel as a set of individual time series for different countries and present time series plots of GNI per capita for sets of countries. The following graph presents a collection of time series for a set of large developed economies df &lt;- subset(longdata, Country == &quot;UK&quot;| Country == &quot;USA&quot;| Country == &quot;Germany&quot;| Country == &quot;France&quot;| Country == &quot;Japan&quot;| Country == &quot;Ireland&quot;|Country == &quot;Italy&quot;|Country==&quot;Canada&quot;) ggplot(df, aes(x=Year, y=log(rGNIpc), col=Country)) + geom_line(linewidth=1) + xlab(&quot;Year&quot;) + ylab(&quot;log(GNI per capita, PPP)&quot;) + labs(title = &quot;Time series plot&quot;, subtitle=&quot;Evolution of GNI per capita across a set of developed economies&quot;) We observe that from 1973 to 2022 GNI per capita (PPP) evolved in a fairly similar way. In addition, while differences (in proportional terms given the log scale) were larger in 1970s, they converged over time. This is especially strongly pronounced until around the period of the Great Recession after which some relative divergence relative to the US seems to have occurred. It seems that the productivity slowdown which we documented for UK earlier, also seems to be common across the advanced economies, and the divergence relative to the US could be down to the fact that among these US did not experience a slowdown of the same magnitude (subject to the PPP exchange rate adjustments). We can also see that the series fluctuate in a fairly similar way relative to trend 5 indicating that business cycles in different countries tend to be somewhat synchronized. For example, all countries see declines relative to trend during the early 1980s recessions, the Great Recession, and the Covid-19 recession. On the other hand, if we make a similar plot for a set of fast growing (typically Asian) economies, with the US for reference, we observe the following: df &lt;- subset(longdata, Country == &quot;USA&quot;| Country == &quot;South Korea&quot;| Country == &quot;Singapore&quot;| Country == &quot;China&quot;| Country == &quot;Myanmar&quot;| Country == &quot;Indonesia&quot;|Country == &quot;Vietnam&quot;) ggplot(df, aes(x=Year, y=log(rGNIpc), col=Country)) + geom_line(size=1)+ xlab(&quot;Year&quot;) + ylab(&quot;log(GNI per capita, PPP)&quot;) + labs(title = &quot;Time series plot&quot;, subtitle=&quot;Evolution of GNI per capita across a set of developping economies&quot;) While these countries had much lower GNI per capita in the 1970s, they experienced faster overall growth relative to advanced economies over the next decades, leading to a decline in the proportional gap in living standards. At this stage it may be natural to conjecture that typically countries with lower income per capita will grow faster than those with higher income per capita, leading to convergence of living standards over time. Based on the above observations this appears sensible, and is sometimes referred to as the convergence hypothesis. However, we have to be careful because in its basic form the convergence hypothesis does not account for experiences of other countries. For example, a similar plot for a set of countries in Sub-Saharan Africa, yields df &lt;- subset(longdata, Country == &quot;USA&quot;| Country == &quot;Democratic Republic of the Congo&quot;| Country == &quot;Zimbabwe&quot;| Country == &quot;Niger&quot;| Country == &quot;Somalia&quot;) ggplot(df, aes(x=Year, y=log(rGNIpc), col=Country)) + geom_line(size=1)+ xlab(&quot;Year&quot;) + ylab(&quot;log(GNI per capita, PPP)&quot;) + labs(title = &quot;Time series plot&quot;, subtitle=&quot;Evolution of GNI per capita across a set of developed economies&quot;) While the chosen countries had much lower per capita income than US in the beginning of the period, over time living standards have not only not converged, but arguably diverged. To understand the pattern of convergence/divergence further, it may be useful to examine the association between countries’ GNI per capita in 1973 and their typical growth rates over the next decades. To do so, first, let’s calculate each country’s “typical” growth rate form from 1973 to 2019 (not until 2022 to disregard the effects of the Covid-19 recession). There could be different ways to define “typical”. A sensible one is as the counterfactual constant annual growth rate that would have led to the economy growing from its level in 1973 to 2019 (see the previous section). Let \\(Y_{i,t}\\) be country \\(i\\)’s GNI per capita (PPP) in year \\(t\\). Then if \\(Y_{i,t}\\) grew at a constant annual rate of \\(g_{i}\\) then \\[Y_{i,2019} = Y_{i,1973}\\times(1+g_{i})^{46} \\Rightarrow g_{i} = \\left(\\frac{Y_{i,2019}}{Y_{i,1973}}\\right)^{1/46}-1 \\] Construct a new varible equal to the “typical growth rate” from 1973 to 2019: longdata&lt;-longdata %&gt;% group_by(Country) %&gt;% mutate(rGNIpc.gr = (rGNIpc[Year==2019]/rGNIpc[Year==1973])^(1/46)-1) Now, keep only one observation from 1973 for each country: df&lt;-longdata %&gt;% group_by(Country) %&gt;% filter(Year==1973&amp;!is.na(rGNIpc.gr)) Note that we are left with only 97 countries, as for the others data on GNI p.c. for either 1973 or 2019 was missing. The data we are using now is presented below: df %&gt;% arrange(rGNIpc.gr) While this is a cross section of countries in 1973, it includes information on the growth rate for subsequent decades, summarized in a new variable rGNIpc.gr, which was obtained from the full panel dataset. Country differences in average annual growth rates over the period can be observed below: ggplot(df,aes(x=rGNIpc.gr,y=fct_reorder(Country,rGNIpc.gr))) + geom_bar(stat=&quot;identity&quot;, aes(fill=Region)) + xlab(&quot;Average annual growth rate, 1973-2019&quot;) + ylab(&quot;Country&quot;) + labs(title = &quot;Bar chart&quot;, subtitle=&quot;Countries ranked by average growth rate of GNI per capita&quot;) + theme(axis.text.y = element_text(size=4)) We observe that there is a large concentration of countries from Sub-Saharan Africa, Middle East and North Africa, and Latin America and the Caribbean among slowest growing countries. If we now plot initial GNI p.c. (in 1973) against subsequent growth rates we obtain ggplot(df,aes(x=log(rGNIpc),y=(rGNIpc.gr), color=Region)) + geom_point() + xlab(&quot;log(GNI per capita, 1973)&quot;) + ylab(&quot;Annual growth rate, 1973 - 2019&quot;) + labs(title = &quot;Scatter plot&quot;, subtitle=&quot;Initial per capita income and subsequent growth rates&quot;) #+ facet_wrap(Region~., scales=&quot;free&quot;) If there was systematic convergence across all countries, we would have observed that higher initial GNI per capita associates with lower subsequent growth rates. However, the graph does not seem to exhibit such pattern. In fact, if we calculate the correlation coefficient between the two variables cor(log(df$rGNIpc),df$rGNIpc.gr) ## [1] 0.0828161 it turns out that the association between the two are in fact positive even if small. In the sample of 97 countries we work with, countries with high GNI per capita in 1973, also tended to grow faster on average during 1973-2019. If anything, we observe divergence, rather than convergence. One aspect of this is that countries from Sub-Saharan Africa, Middle East and North Africa, and Latin America and Caribbean tend to be found in the bottom left quadrant of the graph. If we were to plot excluding these three regions df2 &lt;- subset(df, Region!=&quot;Sub-Saharan Africa&quot;&amp;Region !=&quot;Middle East and North Africa&quot;&amp;Region !=&quot;Latin America and Caribbean&quot;) ggplot(df2,aes(x=log(rGNIpc),y=(rGNIpc.gr), color=Region)) + geom_point() + xlab(&quot;log(GNI per capita, 1973)&quot;) + ylab(&quot;Annual growth rate, 1973 - 2019&quot;) + labs(title = &quot;Scatter plot&quot;, subtitle=&quot;Initial per capita income and subsequent growth rates&quot;) #+ facet_wrap(Region~., scales=&quot;free&quot;) we observe relationship that appears to be indeed negative. Calculating the correlation coefficient cor(log(df2$rGNIpc),df2$rGNIpc.gr) ## [1] -0.54457 confirms that the association is negative and stronger than before (in terms of the magnitude of the coefficient). Nonetheless, it is also clear that even in the final subset of the data (which was in any case obtained somewhat arbitrarily) countries of similar initial income tend to have quite different growth experiences over time. Understanding the reasons for the obseved convergence between countries (and the observed lack of convergence for some) is beyond the scope of this discussion, but is something you will return to during your course. References "],["ch2.html", "Chapter 3 Representing climate change 3.1 Global trends 3.2 UK trends", " Chapter 3 Representing climate change This chapter uses data from various public sources to represent key trends related to climate, in global and UK context. For ease of replication, all the data used in the chapter is available as an Excel file data_ch2.xlsx with different datasets saved as different tabs. To replicate the rest of the chapter on your own R installation, download the file and place it inside a folder on your computer. Then set the working directory in R to the folder where you placed the file. On my machine this is the following: setwd(&quot;/home/emil/Desktop/book&quot;) In addition, run the following code to install all the R libraries that will be used for the analysis install.packages(&quot;readxl&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;ggplot2&quot;) install.packages(&quot;forcats&quot;) and load them library(readxl) library(dplyr) library(ggplot2) library(forcats) 3.1 Global trends 3.1.1 Monthly global surface temperature This section uses monthly data on global surface (land and ocean) temperature from Rohde and Hausfather (2020) available here. For ease of replication, the data has been saved in the sheet gst of the data_ch2.xlsx Excel file. gst &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet=&quot;gst&quot;) head(gst) The data contains 2079 monthly observations (from January 1850 to March 2023) of average monthly global surface temperatures, reported in terms of temperature anomalies (i.e., differences) relative to average temperatures in the corresponding month from January 1951 to December 1980. For the purpose of producing time-series plots, combine the Year and Month variables into a single variable Date gst$Date&lt;-as.Date(with(gst,paste(Year,Month,&quot;01&quot;,sep=&quot;-&quot;)),&quot;%Y-%m-%d&quot;) Then plotting monthly temperature anomalies against time yields the following ggplot(gst, aes(x=Date, y=TemperatureAnomaly)) + geom_line(col=&quot;blue&quot;) + geom_hline(yintercept=0, lty=&quot;dashed&quot;, col=&quot;black&quot;, linewidth=1) + geom_segment(y=0,yend=0, x=as.Date(&quot;1951-01-01&quot;), xend=as.Date(&quot;1980-12-01&quot;), col=&quot;red&quot;, linewidth=1) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Average global monthly temperature anomalies&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Degrees relative to 1951-1980 average&quot;) From the 1850s until around the 1910s average global temperatures were approximately stable, at levels around 0.3 degrees below the 1951-1980 average. There was a pronounced upward trend from the 1910s until the 1940s. Temperatures remained relatively stable until the 1970s. Afterwards, they have been rising steadily and as of 2023 are around 1 degree above the 1951-1980 average. Throughout the whole period average global temperatures have risen by more than 1.3 degrees Celsius. While the overall trend is clearly visible, temperature anomalies exhibit large fluctuations at monthly frequency. One way to represent the trend more clearly is to convert the monthly data to 10-year averages. # Create new data frame based on the original one, and create a variable for the decade gst.decade &lt;- gst %&gt;% mutate(Decade = floor(Year/10)*10) # Create a new variable which equals the mean monthly anomaly for all months in each decade gst.decade &lt;- gst.decade %&gt;% group_by(Decade) %&gt;% mutate(aveTempAnomaly = mean(TemperatureAnomaly)) # Keep only one observation per decade gst.decade &lt;- gst.decade %&gt;% group_by(Decade) %&gt;% filter(row_number() == 1) # Remove observations for the 2020-2029 decade, as sample is smaller gst.decade &lt;- subset(gst.decade, Decade&lt;2020) # Report a table of average temperatures by decade tab &lt;- cbind(gst.decade$Decade, gst.decade$aveTempAnomaly) tab &lt;- gst.decade %&gt;% select(c(&quot;Decade&quot;, &quot;aveTempAnomaly&quot;)) tab The table of 10-year averages confirms the above discussion. The information from the table can be equivalently presented as a time-series line plot ggplot(gst.decade, aes(x=Decade, y=aveTempAnomaly)) + geom_point(col=&quot;blue&quot;) + geom_line(col=&quot;blue&quot;)+ geom_hline(yintercept=0, lty=&quot;dashed&quot;, col=&quot;black&quot;, linewidth=1) + geom_segment(y=0,yend=0, x=1950, xend=1980, col=&quot;red&quot;, linewidth=1) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Decade averages of average global monthly temperature anomalies&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Degrees relative to 1951-1980 average&quot;) or a bar chart ggplot(gst.decade, aes(x=as.factor(Decade), y=aveTempAnomaly)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;blue&quot;)+ geom_hline(yintercept=0, lty=&quot;dashed&quot;, col=&quot;black&quot;, linewidth=1) + geom_segment(y=0,yend=0, x=10.5, xend=13.5, col=&quot;red&quot;, linewidth=1) + labs(title=&quot;Bar chart&quot;, subtitle = &quot;Decade averages of average global monthly temperature anomalies&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Degrees relative to 1951-1980 average&quot;) In summary, since 1850 there has been a marked increase in global surface temperatures, occurring over two distinct stages - 1910s to 1940s and then 1970s to present. # Clear R environment rm(list = ls()) 3.1.2 Changes in ice mass This section uses data from NASA/JPL (2019), on the Antarctic ice mass measured by satellites, available here. For ease of replication, the data has been saved in the sheet ice of the data_ch2.xlsx Excel file. antarctic &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet=&quot;ice&quot;) head(antarctic) The data is an irregularly sampled time series: time is measured as year, reported in decimal form depending on the point in the year when satellites made a measurement. The mass of Antarctic ice is reported as anomaly (i.e., change) in gigatonnes, relative to February 2002. Plotting the Antarctic mass anomaly against time yields ggplot(antarctic, aes(x=Time, y=Mass)) + geom_line(col=&quot;blue&quot;) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Change in Antarctica ice mass&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Gigatonnes, Change relative to 2002&quot;) We observe that the mass of the Antarctic ice cap has decreased by around 3000 gigatonnes from 2002 to 2023. # Clear R environment rm(list = ls()) 3.1.3 Sea level This section uses data from MEaSUREs (2023), on the global mean sea level measured by satellites, available here. For ease of replication, the data has been saved in the sheet sea of the data_ch2.xlsx Excel file. sea &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet=&quot;sea&quot;) head(sea) Similarly to the data on ice mass, this data is an irregularly sampled time series: time is measured by year reported in decimal form depending on the point in the year when satellites made a measurement. The average global sea level (GMSL) is reported in the form of anomaly (i.e., change) in millimeters, relative to January 1993. Plotting the mean seal level anomaly against time yields ggplot(sea, aes(x=Time, y=GMSL)) + geom_line(col=&quot;blue&quot;) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Global mean sea level change&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;mm, Change relative to 1993&quot;) We observe that from 1993 to 2023, global mean sea level has raised by approximately 100 mm (or 10 cm). # Clear R environment rm(list = ls()) 3.1.4 CO2 concentration It is well understood that one of the key drivers of changes in the climate, is changes in the concentration of greenhouse gases in the atmosphere. Greenhouse gases (including CO2, methane, NO and others) absorb the radiation of heat reflected by the Earth surface and cause heating of the atmosphere. This section uses monthly time-series data on atmospheric carbon dioxide (CO2) levels measured by NOAA at Mauna Loa Observatory, Hawaii, since 1958. The data comes from Tans and Keeling (2023), and is available here. For ease of replication, the data has been saved in the sheet co2 of the data_ch2.xlsx Excel file. Loading, preparing, and printing the first few rows of data co2df &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet = &quot;co2&quot;) co2df$Time &lt;- as.Date(co2df$Time) head(co2df) we observe that data is monthly, from March 1958 to July 2023. Atmospheric CO2 levels (the variable co2) are measured in parts per million. Plotting CO2 levels against time yields ggplot(co2df, aes(x=Time, y=co2)) + geom_line(col=&quot;blue&quot;)+ labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Atmospheric CO2 levels measured at Mauna Loa Observatory&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;CO2, parts per million&quot;) Atmospheric concentration of CO2 has raised steadily from 315 ppm in March 1958 to 422 ppm in July 2023. We observe that CO2 levels fluctuate seasonally, but fluctuations are small relative to the long run trend. # Clear R environment rm(list = ls()) 3.1.5 CO2 emissions There is evidence from ice-core data (e.g., see here) that CO2 concentrations in the atmosphere have varied considerably over hundreds of thousands of years, driving cycles of warming and cooling of the planet. However, current CO2 concentrations are unprecedented, and a key reason for this is human activity, especially the release of greenhouse gases from fossil fuels which has increased considerably since the Industrial Revolution. This section uses annual time-series data on the World’s total CO2 emissions from fossil fuels. The data comes from Global Carbon Budget (2022a), and is available here. For ease of replication, the data has been saved in the sheet co2emissions of the data_ch2.xlsx Excel file. Load the data and print first few rows co2world &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet = &quot;co2emissions&quot;) head(co2world) The data contains annual observations from 1750 until 2021 of the global CO2 emissions from fossil fuels, measured by the variable co2 in tonnes. Given the scale of measurement, it is convenient to change the unit of measurement to billions of tones, by dividing the series by 1000000000: co2world$co2 &lt;- co2world$co2/1000000000 Plotting CO2 emissions against time yields ggplot(co2world, aes(x=Year, y=co2)) + geom_line(col=&quot;blue&quot;)+ labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Global CO2 emissions from fossil fuels&quot;) + xlab(&quot;Year&quot;) + ylab(&quot;Billions of tonnes&quot;) It can be observed that CO2 emissions from human activity have increased sharply since 1750, and at an increasing rate for most of the 20th century. # Clear R environment rm(list=ls()) 3.1.6 CO2 emissions and GNI per capita As we have already seen in the Topic of GNI per capita, at country level CO2 emissions per capita associate closely with the level of economic development measured by GNI per capita (PPP). While the associations was already illustrated in the previous topic, we also represent it here for completeness. Again, we use cross sectional data on GNI p.c. (PPP) and CO2 emissions for 212 countries. The data comes from the World Bank’s World Development Indicators database, and is available here. For ease of replication, the data has been saved in the sheet gni_co2_pc_2019 of the data_ch2.xlsx Excel file. Load the data and print first few rows gnico22019 &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet = &quot;gni_co2_pc_2019&quot;) head(gnico22019) ggplot(gnico22019, aes(x=log(GNIpc), y=log(CO2pc))) + geom_point(col=&quot;blue&quot;)+ labs(title=&quot;Scatterplot&quot;, subtitle = &quot;GNI p.c. (PPP) and CO2 emissions p.c., 2019&quot;) + xlab(&quot;log(International Dollars per capita)&quot;) + ylab(&quot;log(Metric tonnes per capita)&quot;) Again, we can see that countries with high per-capita income, also tend to have high per-capita CO2 emissions. # Clear R environment rm(list = ls()) 3.2 UK trends 3.2.1 UK temperatures The data on temperature anomalies discussed above represented average global temperature anomalies, but climate varies geographically, and the overall change in climate affects different regions differently. We now turn attention to specific trend related to the climate of the UK. This section uses annual time-series data on annual average temperature in the UK. The data comes from Met Office (2023a), and is available here. For ease of replication, the data has been saved in the sheet uktemp of the data_ch2.xlsx Excel file. Loading the data and printing the first few rows uktemp &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet = &quot;uktemp&quot;) head(uktemp) the data contains 139 annual observations (from 1884 to 2022) of the annual average temperature in the UK, measured in degrees Celsius. Plotting temperatures against time ggplot(uktemp, aes(x=Year, y=AnnualMeanTemperature)) + geom_line(col=&quot;blue&quot;) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Average annual temperature in UK&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Degrees&quot;) we observe that while temperature fluctuates considerably at annual frequency, overall there is a positive trend (possibly non-monotonic). Average annual temperatures in the end of the 19th century tended to be around 8 degrees, but have been typically above 9.5 degrees in the last years. For purpose of comparison UK trends to the global trend documented above, we can measure temperatures in terms of anomalies relative to the 1951-1980 average. Construct a new variable, AnnualAnomaly equal to the difference between the temperature in a given year and the average of annual temperatures from 1951 to 1980: mean5180 &lt;- mean(subset(uktemp, Year&gt;=1951 &amp; Year&lt;=1980)$AnnualMeanTemperature) uktemp$AnnualAnomaly &lt;- uktemp$AnnualMeanTemperature - mean5180 Plotting the annual anomaly against time ggplot(uktemp, aes(x=Year, y=AnnualAnomaly)) + geom_line(col=&quot;blue&quot;) + geom_hline(yintercept=0, lty=&quot;dashed&quot;, col=&quot;black&quot;, linewidth=1) + geom_segment(y=0,yend=0, x=1951, xend=1980, col=&quot;red&quot;, linewidth=1) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Average annual temperature anomalies, UK&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Degrees relative to 1951-1980 average&quot;) we observe that the pattern of temperatures in the UK looks very similar to the global pattern. Of course, it should be noted that measurement is not directly comparable - for one, global data was available at monthly, while UK at annual frequency. Furthermore, global temperatures were averages across land and ocean surface, while UK temperatures are land surface only. Again, we can provide a clearer understanding of the long term trend if we average out annual fluctuations, for example, by converting annual data, to data on 10-year averages (as before): # Create a variable measuring decade uktemp.decade &lt;- uktemp %&gt;% mutate(Decade = floor(Year/10)*10) # Create variable aveTempAnomaly equal to the average of annual temperatures for the corresponding decade. uktemp.decade &lt;- uktemp.decade %&gt;% group_by(Decade) %&gt;% mutate(aveTempAnomaly = mean(AnnualAnomaly)) # Keep single observation for decade uktemp.decade &lt;- uktemp.decade %&gt;% group_by(Decade) %&gt;% filter(row_number() == 1) # Remove observations for &quot;incomplete&quot; decades uktemp.decade &lt;- subset(uktemp.decade, Decade&lt;2020&amp;Decade&gt;1880) # Plot 10-year average temperatures against corresponding decades ggplot(uktemp.decade, aes(x=Decade, y=aveTempAnomaly)) + geom_point(col=&quot;blue&quot;) + geom_line(col=&quot;blue&quot;)+ geom_hline(yintercept=0, lty=&quot;dashed&quot;, col=&quot;black&quot;, linewidth=1) + geom_segment(y=0,yend=0, x=1950, xend=1980, col=&quot;red&quot;, linewidth=1) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Decade averages of average annual UK temperature anomalies&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Degrees relative to 1951-1980 average&quot;) The pattern for UK is very similar to the global pattern documented before, with the notable difference that UK temperatures followed a brief downward trend from 1940s to the 1960s. # Clear R environment rm(list = ls()) 3.2.2 UK Rainfall This section uses annual time-series data on annual average rainall in the UK. The data comes from Met Office (2023b), and is available here. For ease of replication, the data has been saved in the sheet ukrain of the data_ch2.xlsx Excel file. Loading the data and printing the first few rows ukrain &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet = &quot;ukrain&quot;) head(ukrain) The data consists of 186 annual observations (from 1836 to 2021) of the average annual rainfall in UK, measured in millimeters. Plotting average annual rainfall against time yields ggplot(ukrain, aes(x=Year, y=Rain)) + geom_line(col=&quot;blue&quot;) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Average annual rainfall in UK&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Millimeters&quot;) Relative to average temperature, we can observe that average rainfall tends to be quite more volatile at annual frequency (it is relatively common for very wet and very dry years to occur, and there are large differences between wet and dry years). Nonetheless, we can also observe that there is an increasing long-term trend - typical rainfall in the begining of the 19th century was around 1000 mm, while in recent decades typical years see 1200 mm or rain. Similarly to prior sections we can represent this more clearly by reporting rainfall in terms of annual anomalies (differences) relative to the 1951-1980 average # Calucalte mean annual rainfall for 1951-1980 mean5180 &lt;- mean(subset(ukrain, Year&gt;=1951 &amp; Year&lt;=1980)$Rain) # Calculate annual anomaly as difference between actual annual rainfall and the 1951-1980 average ukrain$AnnualAnomaly &lt;- ukrain$Rain - mean5180 # Plot annual anomalies against year ggplot(ukrain, aes(x=Year, y=AnnualAnomaly)) + geom_line(col=&quot;blue&quot;) + geom_hline(yintercept=0, lty=&quot;dashed&quot;, col=&quot;black&quot;, linewidth=1) + geom_segment(y=0,yend=0, x=1951, xend=1980, col=&quot;red&quot;, linewidth=1) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Annual UK rain anomalies&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Millimeters relative to 1951-1980 average&quot;) where we can clearly see that typical years recently are wetter than typical years in 1951-1980, and 1951-1980 are on average wetter than in the begining of the observation window. As before, to focus on trends rather than fluctuations, represent the data in terms of 10-year averages: # Create a variable measuring the decade of observation ukrain.decade &lt;- ukrain %&gt;% mutate(Decade = floor(Year/10)*10) # Create a variable measuring the average anomaly per decade ukrain.decade &lt;- ukrain.decade %&gt;% group_by(Decade) %&gt;% mutate(aveAnomaly = mean(AnnualAnomaly)) # Keep single observation per decade ukrain.decade &lt;- ukrain.decade %&gt;% group_by(Decade) %&gt;% filter(row_number() == 1) # Remove incomplete decades ukrain.decade &lt;- subset(ukrain.decade, Decade&gt;1830&amp;Decade&lt;2020) # Plot ggplot(ukrain.decade, aes(x=Decade, y=aveAnomaly)) + geom_point(col=&quot;blue&quot;) + geom_line(col=&quot;blue&quot;)+ geom_hline(yintercept=0, lty=&quot;dashed&quot;, col=&quot;black&quot;, linewidth=1) + geom_segment(y=0,yend=0, x=1950, xend=1980, col=&quot;red&quot;, linewidth=1) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Decade averages of annual rain anomalies, UK&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Millimeters relative to 1951-1980 average&quot;) We can see that recent decades typically experienced about 100 mm (10 cm) annual rain, than in 1951-1980. # Clear R environment rm(list = ls()) 3.2.3 UK CO2 emissions This section uses annual time-series data on UK’s CO2 emissions. The data comes from Global Carbon Budget (2022b), and is available here. For ease of replication, the data has been saved in the sheet ukco2 of the data_ch2.xlsx Excel file. Load the data and print first few rows ukco2 &lt;- read_xlsx(&quot;data_ch2.xlsx&quot;, sheet = &quot;ukco2&quot;) head(ukco2) The dataset contains annual data (from 1750 to 2021) on estimates of UK’s - production-based CO2 emissions, measured by the variable co2 in tonnes; and - consumption-based CO2 emissions, measured by the variable co2cons in tonnes. Production-based emissions record the amount of CO2 emitted through production within a country’s own borders. Consumption-based emissions record the amount of CO2 emitted to produce the goods and services consumed within an economy (i.e., accounting for trade). While production-based emissions are available since 1750, consumption-based emissions are only available since 1990. Given the scale of the variables, it is appropriate to report emissions in terms of millions of tonnes, rather than tonnes. To do this, divide emissions in tonnes by 1000000: ukco2$co2 &lt;- ukco2$co2/1000000 ukco2$co2cons &lt;- ukco2$co2cons/1000000 Plotting UK’s production-based CO2 emissions against time yields ggplot(ukco2, aes(x=Year, y=co2)) + geom_line(col=&quot;blue&quot;) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Annual production-based CO2 emissions, UK&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Millions of tonnes&quot;) Since the outset of the Industrial Revolution, UK’s CO2 emissions increased at an approximately exponential rate, peaking in the 1970s at levels around 650 millions of tonnes per year (and seeing a relative decline at the time of WW1 and the Great Depression). Following the sectoral restructuring in the economy away from manufacturing CO2 emissions embodied in production have declined to about 346 millions of tonnes as of 2022. However, plotting consumption and production based emissions on the same graph for the same time window ggplot(ukco2, aes(x=Year)) + geom_line(aes(y=co2,col=&quot;Production&quot;)) + geom_line(aes(y=co2cons,col=&quot;Consumption&quot;)) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Annual CO2 emissions, UK&quot;, col = &quot;Measure&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Millions of tonnes&quot;) + scale_color_manual(values=c(&quot;red&quot;, &quot;blue&quot;)) or only for the part of the window where consumption-based measures are available ggplot(ukco2, aes(x=Year)) + geom_line(aes(y=co2,col=&quot;Production&quot;)) + geom_line(aes(y=co2cons,col=&quot;Consumption&quot;)) + labs(title=&quot;Time series line plot&quot;, subtitle = &quot;Annual CO2 emissions, UK&quot;, col = &quot;Measure&quot;) + xlab(&quot;Time&quot;) + ylab(&quot;Millions of tonnes&quot;) + xlim(c(1988,2022)) + scale_color_manual(values=c(&quot;red&quot;, &quot;blue&quot;)) we observe that while UK’s production embodies much less CO2 emissions than its consumption (i.e., UK is a net importer of “CO2” emissions). Still, even consumption-based CO2 emissions have seen a decline since the early 2000s. References "],["ch3.html", "Chapter 4 Representing income inequality 4.1 Distribution of income in the FRS 2016/17 4.2 Cross-country differences in income inequality 4.3 Income inequality over time", " Chapter 4 Representing income inequality This chapter turns attention to representing the extent of income inequality using data. For ease of replication, all the data used in the documented is available as an Excel file data_ch3.xlsx with different datasets saved as different tabs. To replicate the rest of the document in your own R installation, download the file and place it inside a folder on your computer. Then set the working directory in R to the folder where you placed the file. On my computer this is done as follows: setwd(&quot;/home/emil/Desktop/book&quot;) In addition, run the following code to install all the R libraries that will be used for the analysis install.packages(&quot;readxl&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;ggplot2&quot;) install.packages(&quot;forcats&quot;) install.packages(&quot;pracma&quot;) install.packages(&quot;scales&quot;) and load them library(readxl) library(ggplot2) library(scales) library(dplyr) library(forcats) library(pracma) 4.1 Distribution of income in the FRS 2016/17 The Family Resources Survey (FRS), carried out by the ONS, with the NatCen, and NISRA, is an annual survey collecting information on a representative sample of UK households (Office for National Statistics, Social and Vital Statistics Division, Department for Work and Pensions, National Centre for Social Research, 2023). It includes rich information on the incomes and characteristics of individuals and households. This section uses an excerpt from the FRS 2016/17 individual level data to provide some examples of representing key cross-sectional patterns related to the unequal distribution of income, and to discuss how income inequality can be measured. The data is not open-access, hence it is not provided with this document. Given this you will not be able to replicate this section (without obtaining the data), but the structure of the data is explained in sufficient detail for you to understand the code. 4.1.1 Summary of data Let’s start by loading the data and listing the first few rows frs &lt;- read_xlsx(&quot;FRS2017.xlsx&quot;) head(frs) The data is a cross-section of 33252 observations on four variables from the 2016/17 financial year. An observation (row of the data) corresponds to an individual (aged 16 and over). The four variables are - age - recording the age of the individual in bands - educ - recording the highest education attainment of the individual in bands - sex - recording the sex of the individual - income - recording the individual’s total weekly income from all sources (including pensions and transfers) before tax. To prepare the data for analysis 1. note that age, educ and sex are categorical (factor) variables which we can declare explicitly to avoid problems # Declare variables as categorical frs$age &lt;- as.factor(frs$age) frs$educ &lt;- as.factor(frs$educ) frs$sex &lt;- as.factor(frs$sex) # Change order of categories in `educ` in order of average income per group frs$educ &lt;- fct_reorder(frs$educ, frs$income, .fun=mean) note that income is recorded in the form of weekly income (i.e., measured in pounds per week). While equivalent, it is often more natural to think in terms of monthly or annual income. For this reason we will convert the income variable into approximate equivalent annual income by multiplying weekly income by 52 (the number of weeks in a year frs$income &lt;- frs$income*52 Now income is measured in pounds per year, and corresponds to total income from all sources before tax. Hencefort, by “income” we will mean specifically this notion of income. It should be noted that inequality metrics discussed below are specific to this particular definition of income, and would be different for alternative income concepts (e.g., income after taxes, or labour income only). To get a sense of the data, calculate some summary statistics for all variables in the dataframe summary(frs) ## age educ sex ## Age 16 to 24 :2456 GCSE or equivalent :11265 Female:17509 ## Age 25 to 34 :4821 A-level or equivalent: 5139 Male :15743 ## Age 35 to 44 :5334 Degree of equivalent : 7795 ## Age 45 to 54 :5678 Postgraduate : 3162 ## Age 55 to 64 :5734 NA&#39;s : 5891 ## Age 65 and over:9229 ## income ## Min. : 0 ## 1st Qu.: 10088 ## Median : 17576 ## Mean : 22751 ## 3rd Qu.: 28340 ## Max. :885768 For categorical variables summary() reports the number of individuals in different categories. For example, we can see that the sample consists of 17509 females and 15743 males; most individuals’ highest educational attainment is GSCE or equivalent (11265 individuals). For numerical variables (in this case only income) summary() reports key summary statistics from the distribution. At this stage we can already see that income is very unequally distributed. Unsurprisingly, the minimum of the support of income is 0 (some individuals reported no income), while the richest individual in the data reported annual income of £885768. 25% of individuals in the data receive income below £10088, 50% receive income below £17576 (the median), 75% receive income below £28340. Mean income (at £22751) is above median (at £17576) indicating that the distribution is asymmetric. 4.1.2 Distribution of income: dispersion and skewness To understand the distribution of income in the data, we start by plotting a histogram of income ggplot(frs) + geom_histogram(aes(x=income), bins = 100, fill=&quot;red&quot;) + xlab(&quot;Annual income, GBP&quot;) + ylab(&quot;Number of observations&quot;) + labs(title = &quot;Histogram&quot;, subtitle = &quot;Distribution of individual annual pre-tax income, FRS 2017&quot;) Note that by default the histogram is plotted over the whole support of income in the sample (i.e. from £0 to £885768). This makes the graph look somewhat peculiar - it looks as if there are no observations with income above £375000 but this is misleading as in fact there are (we know one observation has £885768) but the corresponding bars are so small that they are effectively invisible. To focus on the part of the distribution where most of the mass lies, we can restrict the horizontal axis to the 99th quantile of the distribution only ggplot(frs) + geom_histogram(aes(x=income), bins = 100, fill=&quot;red&quot;) + xlab(&quot;Annual income, GBP&quot;) + ylab(&quot;Number of observations&quot;) + xlim(0,quantile(frs$income,0.99)) + labs(title = &quot;Histogram&quot;, subtitle = &quot;Distribution of individual annual pre-tax income, FRS 2017, Bottom 99 percent&quot;) representing the income distribution within the bottom 99 percent of individuals by income only. Two features of the distribution are immediately clear: 1. the distribution is highly disperse - there are large income differences between individuals. 2. the distribution is very strongly positively skewed - characterised by a long and thin right tail, with most observations found in the extreme left of the distribution. It is clear that income is very unequally distributed. One implication of this is that when we use measures of central tendency (such as mean or median income) to quantify living standards within a country (for example, in measures such as GNI or GDP per capita) we should recognise the fact that they do not necessarily account for “typical” incomes - relatively few individuals earn income very close to the mean or the median. Some important aspects of inequality are reflected in standard summary statistics. For example, as we observed above, mean income (£22751) considerably exceeds median income (£17576), which is a feature the observed asymmetry (skewness) of the distribution. Exactly 50% of individuals of the data receive income below £17576 (the median) but a much larger fraction of individuals receive income well below the mean. To gain further quantitative understanding of the unequal distribution of income, it is informative to calculate some quantiles quantile(frs$income, seq(0.1, 0.9, by=0.1)) ## 10% 20% 30% 40% 50% 60% 70% 80% 90% ## 4264 8476 11544 14508 17576 20956 25324 31824 43368 10% of individuals in the data receive less than £4264 pr year; 20% receive less than £8476 and so forth. One thing that we observe is that the fraction of people receiving less than average income is more than 60% (but less than 70%). Comparisons between different quantiles is very informative about both dispersion and assymetry (and as we will see later is the basis of some popular quantitative measures of income inequality). In particular, we observe large differences between quantiles (indicatig disperison) with differences increasing at higher incomes (indicating assymetry). 4.1.3 Income differences between and within groups of individuals The above discussion referred to overall differences in income between individuals. Important aspects of inequality are about differences between (and within) groups. This section illustrates such differences on the basis of the categorical variables observed in the data: sex, age, educ. 4.1.3.1 Inequality between sexes It is well known that there are systematic income differences between men and women. To explore these within this data, start by plotting separate histograms by sex: ggplot(frs, aes(x=income, fill=sex, y = ..density..)) + geom_histogram(bins = 50, position=&quot;dodge&quot;) + scale_fill_manual(values=c(&quot;blue&quot;, &quot;red&quot;)) + xlab(&quot;Annual income, GBP&quot;) + ylab(&quot;Density&quot;) + xlim(0,quantile(frs$income,0.99)) + labs(title = &quot;Histogram&quot;, subtitle = &quot;Distribution of individual annual pre-tax income, FRS 2017, By sex&quot;) It can be seen that the income distributions for men and women are different and, in particular, it appears that the distribution for men is shifted to the right relative to the distribution for women (for example, relative to men, women are more likely to be in the left tail of the overall distribution, and less likely in the right tail). To get a more quantitative (if less rich) description of the differences, we can obtain a set of summary statistics (mean, median, 10th percentile, 90th percentile) for income by sex: frs %&gt;% group_by(sex) %&gt;% summarise(mean=mean(income), median = median(income), q10 = quantile(income, 0.1), q90 = quantile(income, 0.9)) Average income for men in the sample (£27992) far exceeds average income for women (£18037) and similarly for medians, 10th percentile and 90th percentile. For example, 90 percent of women receive less than £35266 while 90% of mean receive less than £52416. As discussed before, a convenient way of presenting key summary statistics (25th percentile, median, 75th percentile, interquartile range) is through a box plot: ggplot(frs,aes(y=income, fill=sex))+ geom_boxplot(alpha=0.5, outlier.shape = NA) + ylim(0,quantile(frs$income,0.95)) + scale_fill_manual(values=c(&quot;blue&quot;, &quot;red&quot;)) + xlab(&quot;&quot;) + ylab(&quot;Annual income, GBP&quot;) + labs(title = &quot;Box plot&quot;, subtitle = &quot;Annual income by sex, FRS 2017&quot;, fill=&quot;&quot;) + theme(axis.text.y = element_blank())+ coord_flip() Indeed we observe systematic differences in the distribution on income between men and women. It should be noted, however, that this accounts for only small part of the overall income inequality as the distributions of incomes within groups are still very unequal. 4.1.3.2 Income differences between age groups It is similarly well known income varies systematically over the life cycle, and some of the observed overall differences in incomes reflects differences in individuals’ age. Given that we have 6 age groups, histograms will tend to be somewhat uninformative, but as before we can obtain a set of summary statistics for income by age frs %&gt;% group_by(age) %&gt;% summarise(mean=mean(income), median = median(income), q10 = quantile(income, 0.1), q90 = quantile(income, 0.9)) or use a box plot ggplot(frs,aes(y=income, fill=age))+ geom_boxplot(outlier.shape = NA) + ylim(0,quantile(frs$income,0.95)) + xlab(&quot;&quot;) + ylab(&quot;Annual income, GBP&quot;) + labs(title = &quot;Box plot&quot;, subtitle = &quot;Income distribution by age, FRS 2017&quot;, fill=&quot;&quot;) + scale_fill_brewer(palette = &quot;Reds&quot;) + theme(axis.text.x = element_blank()) The age profile of income over age probably reflects life-cyclical patterns of labour income, where income increases on average as people progress through their careers, and then declines as they enter retirement. This clarifies that there are systematic income differences by age. It should be noted, however, that this accounts for only small part of the overall income inequality as distributions of incomes within age groups are still very unequal. 4.1.3.3 Income differences by education Repeating the analysis for individuals with different education in terms of summary statistics frs %&gt;% group_by(educ) %&gt;% summarise(mean=mean(income), median = median(income), q10 = quantile(income, 0.1), q90 = quantile(income, 0.9)) and box plot ggplot(frs,aes(y=income, fill=educ))+ geom_boxplot(outlier.shape = NA) + ylim(0,quantile(frs$income,0.95)) + xlab(&quot;&quot;) + ylab(&quot;Annual income, GBP&quot;) + labs(title = &quot;Box plot&quot;, subtitle = &quot;Distribution of income by age, FRS 2017&quot;, fill=&quot;&quot;) + scale_fill_brewer(palette = &quot;Reds&quot;) + theme(axis.text.y = element_blank())+ coord_flip() we observe that more education associates strongly with higher income, likely reflecting returns to education. For example, the median income among those with postgraduate degree (£31096) is just slightly below the 80th percentile of the overall income distribution (£31824), while the median for those with GCSE or equivalent (£16068) is just slightly above the 40th percentile of the overall income distribution (£14508). Again, while we observe systematic income differences between education groups, there is also significant income inequality within groups. 4.1.4 Quantitative measures of income inequality While histograms allow us to represent the distribution of income in all its complexity, we are often interested in comparing the extent of inequality in different income distributions. For example: - we might be interested in comparing different countries by income inequality. This amounts to comparing the whole distribution of income in Country A to the distribution of income in Country B. - we might be interested in analyzing how income inequality changes over time in a given country. This amounts to comparing the distribution of income in Year A to the distribution of income in Year B. As comparisons between histograms could be difficult (as observed) it would be more appropriate to use numerical measures of inequality instead. A numerical measure of inequality, is one that summarizes some aspect of the inequality into a single number. As inequality is a complex phenomenon, there are many different numerical measures, which emphasise different aspects of inequality. While a thorough discussion of different metrics is beyond the scope of the document, this section briefly outlines several popular metrics and illustrates their meaning through the data. 4.1.4.1 Percentile ratios We have already seen that comparison between different percentiles of the distribution is informative about important aspects of inequality. Percentile ratios (or p-ratios) are simply ratios of percentiles. Two common percentile ratios used to quantify inequality of income are the P50P10 ratio (the ratio between median income and the 10th percentile of income) and the P90P50 ratio (the ratio between the 90th percentile of income and median income). For example, for the whole data, we can calculate the 10th, 50th and 90th percentiles, and the corresponding percentile ratios as follows frs %&gt;% summarise(q10 = quantile(income, 0.1), q50 = median(income), q90 = quantile(income, 0.9), p90p50 = q90/q50, p50p10 = q50/q10) We observe that those at the 90th percentile of the distribution have 2.47 times higher income than those at the median; while the latter have 4.12 times more income than those at the 10th percentile. To show how p-ratios can be used to compare inequality across distributions, we can calculate the p-ratios for the income distributions within education groups in the data: frs %&gt;% group_by(educ) %&gt;% summarise(q10 = quantile(income, 0.1), q50 = median(income), q90 = quantile(income, 0.9), p90p50 = q90/q50, p50p10 = q50/q10) We have already seen that overall average and median incomes increase with education. However, we can now see that the distributions within groups become increasingly unequal with higher education. 4.1.4.2 Measures of concentration So far we have discussed two important features of the distribution of income - dispersion and asymmetry. Another important feature, which is somewhat distinct from the former, is that income distributions tend to be highly concentrated. Loosely, this means that relatively small fractions of the overall population receive relatively large shares of the total income. Some of the most popular metrics of income inequality (shares of top 10% or top 1%, GINI coefficient, etc) are in fact measures of concentration. 4.1.4.2.1 Lorenz curve To understand measures of concentration, suppose that we order all individuals in the data by increasing order of their income frs &lt;- frs %&gt;% arrange(income) Calculate the quantile rank of each individual (i.e., the percentile of the overall distribution corresponding to the particular individual’s income) frs &lt;- frs %&gt;% mutate(inc.qrank = row_number(income)/length(income)) Now suppose that we move from the poorest to the richest individual, and for each we record the total income received by herself and those poorer, in a new variable, cuminc (for cummulative income) frs$cuminc &lt;- cumsum(frs$income) Next, divide cuminc by the total amount of income earned by individuals in the data frs$cumincshare &lt;- frs$cuminc/sum(frs$income) to obtain the cummulative income share at each quantile rank. The mapping from quantile rank to cummulative income share is known as a the Lorenz curve. The Lorenz curve for income in the FRS data can be represented graphically as follows ggplot(frs) + geom_line(aes(x=inc.qrank, y=cumincshare), col=&quot;tomato&quot;) + scale_x_continuous(breaks = seq(0,1, by=0.1)) + scale_y_continuous(breaks = seq(0,1, by=0.1)) + xlab(&quot;Quantile of income&quot;) + ylab(&quot;Cummulative share of income&quot;) + labs(title = &quot;Lorenz curve&quot;) From the Lorenz curve, we can observe that, for example - the bottom 50 % of individuals by income receive around 20% of all the income in the sample. Therefore, the top 50% receive around 80%. - the bottom 90% of individuals receive around 68% of all the income. Therefore, the top 10 % receive the remaining 32%. - the top 5% receive around 21% of all income - and so forth. 4.1.4.2.2 Top income shares The points on the Lorenz curve (known as Lorenz coordinates) are the basis of many popular measures of income inequality (and more specifically income concentration). Two common measures are as follows: -the share of income of the top 10 %. We can obtain this by finding the share of the bottom 90 % lorenz_fun &lt;- approxfun(x=frs$inc.qrank, y=frs$cumincshare) lorenz_fun(0.9) ## [1] 0.6804861 implying that the share of the top 10% in the FRS is approximately 32% of all income. This is in line with estimates from administrative data for the UK as a whole. the share of income of the top 1 $. We can obtain this by finding the share of the bottom 99 % lorenz_fun(0.99) ## [1] 0.9218844 implying that the share of the top 1% in the FRS is approximately 9.2% of all income. This seems to be slightly lower than estimates from administrative data for the UK as a whole, likely due to underrepresentation of richest individuals in the survey. 4.1.4.2.3 Gini coefficient Probably the best known measure of income inequality, the Gini coefficient, is in fact a measure of concentration related to the Lorenz curve. The figure below plots the actual empirical Lorenz curve for the FRS (in blue) together with - a counterfactual Lorenz curve for an economy with “perfect equality” (in red). If all individuals in an economy receive the same income (perfect equality), and are ordered arbitrarily along the horizontal axis, then the “poorest” (arbitrarily defined) \\(n\\)% of the population, would be receiving \\(n\\)% of the total income. The Lorenz curve maps \\(n\\) to \\(n\\) and is therefore a straight line with slope 45 degrees. - a counterfactual Lorenz curve for an economy with “perfect inequality” (in green). If all but one individuals in the economy receive no income, and one receives some (and therefore all the income), then the income share of the “all but one” will be 0 (implying horizontal portion of the Lorenz curve over \\([0,1)\\)) and a discontinuous jump at \\(1\\). ggplot(frs) + geom_line(aes(x=inc.qrank, y=cumincshare, col=&quot;Lorenz curve, FRS&quot;), size=1) + geom_segment(x=0, xend=1, y=0, yend=1, aes(col=&quot;Lorenz curve under perfect equality&quot;), size=1) + geom_segment(x=0, xend=1, y=0, yend=0, aes(col=&quot;Lorenz curve under perfect inequality&quot;), size=1) + geom_segment(x=1, xend=1, y=0, yend=1, aes(col=&quot;Lorenz curve under perfect inequality&quot;), size=1) + xlab(&quot;Quantile of income&quot;) + ylab(&quot;Cummulative share of income&quot;) + labs(title = &quot;Lorenz curves and Gini coefficient, 1&quot;, color = &quot;&quot;) Intuitively, the closer is the actual Lorenz curve to the perfect equality one, the more equal is the distribution; the closer to the perfect inequality one, the more unequal is the distribution. The Gini coefficient measures exactly how close the actual Lorenz curve is to the perfect inequality line and more specifically is defined as follows: Let \\(A\\) denote the area between the actual Lorenz curve and the perfect equality line, and \\(B\\) denote the area between the perfect inequality line and the actual Lorenz curve: ggplot(frs) + geom_line(aes(x=inc.qrank, y=cumincshare, col=&quot;Lorenz curve, FRS&quot;), size=1) + geom_segment(x=0, xend=1, y=0, yend=1, aes(col=&quot;Lorenz curve under perfect equality&quot;), size=1) + geom_segment(x=0, xend=1, y=0, yend=0, aes(col=&quot;Lorenz curve under perfect inequality&quot;), size=1) + geom_segment(x=1, xend=1, y=0, yend=1, aes(col=&quot;Lorenz curve under perfect inequality&quot;), size=1) + xlab(&quot;Quantile of income&quot;) + geom_ribbon(aes(x=inc.qrank, ymin = cumincshare, ymax = inc.qrank, fill = &quot;A&quot;), alpha=0.5) + geom_ribbon(aes(x=inc.qrank, ymin = 0, ymax = cumincshare, fill = &quot;B&quot;), alpha = 0.5) + ylab(&quot;Cummulative share of income&quot;) + labs(title = &quot;Lorenz curves and Gini coefficient, 2&quot;, color = &quot;&quot;, fill = &quot;Area&quot;) Then the Gini coefficient is defined as \\[Gini = \\frac{A}{A+B}\\] Note that since \\(A+B=1/2\\), the Gini coefficient is also equal to \\(2A\\) or \\(1-2B\\). It is easy to see that the value of the Gini coefficient is a number between 0 and 1, with 0 indicating perfect equality, and 1 indicating perfect inequality. One way to calculate the Gini coefficient in our data is to obtain the area \\(B\\) as the definite integral of the Lorenz curve from 0 to 1. Integrating the Lorenz curve numerically yields B &lt;- integral(lorenz_fun, 0,1) gini = 1-2*B gini ## [1] 0.4410313 so the Gini coefficient in the FRS data is 0.44. This seems in line with estimates from administrative data for income from all sources before taxes. Unlike other numerical measures, the scale of the Gini coefficient is difficult to interpret in itself. However, as all numerical measures it is useful for comparing the inequality of different distributions, e.g., between countries, or within a country over time, as we see below. # Clear R environment rm(list = ls()) 4.2 Cross-country differences in income inequality The World Inequality Database provides open access to the most extensive available database on the historical evolution of the world distribution of income and wealth, both within countries and between countries. This section uses cross sectional data of countries on a set of measures of income inequality in 2017. The data comes from Alvaredo and Saez (2022), and is available here. For ease of replication, the data has been saved in the sheet WID17 of the data_ch3.xlsx Excel file. Load the data and print first few rows wid2017 &lt;- read_xlsx(&quot;data_ch3.xlsx&quot;, sheet = &quot;WID2017&quot;) wid2017$Country &lt;- as.factor(wid2017$Country) head(wid2017) The dataset contains observations for 48 countries in 2017, on 6 aggregate measures of inequality in pre-tax income. - gini is the Gini coefficient - s10, s1, and s0.1 are the income shares of the top 10%, 1%, and 0.1% - p90p50 and p50p10 are the P90P50 and P50P10 percentile ratios. To get a sense of the data, report a set of summary statistics summary(wid2017) ## Country Year gini s10 s1 ## Argentina: 1 Min. :2017 Min. :0.3779 Min. :27.47 Min. : 7.05 ## Australia: 1 1st Qu.:2017 1st Qu.:0.4394 1st Qu.:33.18 1st Qu.:10.50 ## Belarus : 1 Median :2017 Median :0.5072 Median :37.73 Median :12.86 ## Belgium : 1 Mean :2017 Mean :0.5192 Mean :40.84 Mean :14.35 ## Brazil : 1 3rd Qu.:2017 3rd Qu.:0.5809 3rd Qu.:46.89 3rd Qu.:17.65 ## Bulgaria : 1 Max. :2017 Max. :0.7442 Max. :64.19 Max. :27.06 ## (Other) :42 ## s0.1 p90p50 p50p10 ## Min. : 1.640 Min. :1.676 Min. :4.578 ## 1st Qu.: 3.397 1st Qu.:2.237 1st Qu.:5.080 ## Median : 4.660 Median :2.656 Median :5.403 ## Mean : 4.915 Mean :2.926 Mean :5.589 ## 3rd Qu.: 5.575 3rd Qu.:3.452 3rd Qu.:5.903 ## Max. :12.670 Max. :6.179 Max. :8.298 ## NA&#39;s :8 It is immediately observed, that there are large differences in the values of all income-inequality metrics across countries. For example, the income share of the top 0.1 % of individuals varies from 1.6% to 12.67% across countries. Given the relatively small number of observations, a convenient way to represent cross country differences is through ordered bar charts. Arranging countries in increasing order of Gini coefficients, and representing the value of each country’s Gini coefficient by the height of the corresponding bar yields ggplot(wid2017) + geom_bar(aes(x=fct_reorder(Country, gini), y=gini), stat=&quot;identity&quot;, fill=&quot;red&quot;, col=&quot;black&quot;) + theme(axis.text.y= element_text(size=6)) + xlab(&quot;&quot;) + ylab(&quot;Gini coefficient&quot;) + labs(title = &quot;Gini coefficients across countries&quot;, subtitle = &quot;Pre-tax income from all sources&quot;) + coord_flip() We observe large cross-country differences in terms of Gini coefficients. Within the sample, in terms of Gini coefficients, Slovakia has the most equal income distribution (0.378) and Mexico has the most unequal income distribution (0.744). Producing similar graphs for the other metrics ggplot(wid2017) + geom_bar(aes(x=fct_reorder(Country, s10), y=s10), stat=&quot;identity&quot;, fill=&quot;red&quot;, col=&quot;black&quot;) + theme(axis.text.y= element_text(size=6)) + xlab(&quot;&quot;) + ylab(&quot;Top 10 % income share&quot;) + labs(title = &quot;Top 10% income shares across countries&quot;, subtitle = &quot;Pre-tax income from all sources&quot;) + coord_flip() ggplot(wid2017) + geom_bar(aes(x=fct_reorder(Country, s1), y=s1), stat=&quot;identity&quot;, fill=&quot;red&quot;, col=&quot;black&quot;) + theme(axis.text.y= element_text(size=6)) + xlab(&quot;&quot;) + ylab(&quot;Top 1% income share&quot;) + labs(title = &quot;Top 1% income shares across countries&quot;, subtitle = &quot;Pre-tax income from all sources&quot;) + coord_flip() ggplot(wid2017) + geom_bar(aes(x=fct_reorder(Country, p90p50), y=p90p50), stat=&quot;identity&quot;, fill=&quot;red&quot;, col=&quot;black&quot;) + theme(axis.text.y= element_text(size=6)) + xlab(&quot;&quot;) + ylab(&quot;P90P50 ratio&quot;) + labs(title = &quot;P90P50 ratio across countries&quot;, subtitle = &quot;Pre-tax income from all sources&quot;) + coord_flip() ggplot(subset(wid2017, !is.na(p50p10))) + geom_bar(aes(x=fct_reorder(Country, p50p10), y=p50p10), stat=&quot;identity&quot;, fill=&quot;red&quot;, col=&quot;black&quot;) + theme(axis.text.y= element_text(size=6)) + xlab(&quot;&quot;) + ylab(&quot;P50P10 ratio&quot;) + labs(title = &quot;P50P10 ratio across countries&quot;, subtitle = &quot;Pre-tax income from all sources&quot;) + coord_flip() we observe that there are significant differences in terms of all different measures. Of course, different measures capture different aspects of inequality (e.g., Gini coefficients and top income shares in particular are measures of concentration, while the percentile ratios measure specific aspects of dispersion). Nonetheless, inspecting the graphs, it seems countries with high inequality in one measure, tend to also exhibit high inequality in terms of the other measures. To inspect this relationship more clearly we next present scatterplots showing the association netween Gini coefficients and other metrics. In terms of Gini coefficient and top income shares ggplot(wid2017, aes(x=gini)) + geom_point(aes(y=s10, col=&quot;Top 10%&quot;)) + geom_point(aes(y=s1, col=&quot;Top 1%&quot;)) + geom_point(aes(y=s0.1, col=&quot;Top 0.1%&quot;)) + xlab(&quot;Gini coefficient&quot;) + ylab(&quot;Measure&quot;) + labs(title = &quot;Scatterplot&quot;, subtitle = &quot;Association between Gini coefficient and top income shares, countries&quot;, col = &quot;Income share&quot;) unsurprisingly, we observe very strong positive association - countries with high Gini coefficients tend to also have high top income shares. Of course, this is not surprising as both Gini coefficients and top income shares are fundamentally measures of concentration, capturing similar aspects of income distributions within countries. Perhaps more surprisingly, we observe also very strong association between Gini coefficients and percentile ratios: ggplot(wid2017, aes(x=gini)) + geom_point(aes(y=p50p10, col=&quot;P50P10&quot;)) + geom_point(aes(y=p90p50, col=&quot;P90P50&quot;)) + xlab(&quot;Gini coefficient&quot;) + ylab(&quot;Measure&quot;) + labs(title = &quot;Scatterplot&quot;, subtitle = &quot;Association between Gini coefficient and percentile ratios, countries&quot;, col = &quot;Measure&quot;) In general, the data shows that there are large and systematic differences in income inequality across countries. 4.3 Income inequality over time This section uses a panel dataset for several large developped economies, tracking measures of income inequality from the begining of the 20th century, until 2022. As in the previous section, the data comes from Alvaredo and Saez (2022) and is available here The . For ease of replication, the data has been saved in the sheet WIDpanel of the data_ch3.xlsx Excel file. Load the data and print first few rows panel &lt;- read_xlsx(&quot;data_ch3.xlsx&quot;, sheet = &quot;WIDpanel&quot;) panel$Country &lt;- as.factor(panel$Country) head(panel) We have a panel data in long form, with records of the Gini coefficient and Top 10%, Top 1% and Top 0.1 % income shares, for each country in each year, from 1912 until 2021. The set of countries included levels(panel$Country) ## [1] &quot;Australia&quot; &quot;Canada&quot; &quot;France&quot; &quot;Germany&quot; ## [5] &quot;Japan&quot; &quot;United Kingdom&quot; &quot;United States&quot; are large developed economies. Plotting time series plots of Gini coefficient across time, for each country yields ggplot(panel, aes(x=Year, y=gini, col=Country)) + geom_line() + geom_point() + scale_color_brewer(palette = &quot;Dark2&quot;) + xlab(&quot;&quot;) + ylab(&quot;Gini coefficient&quot;) + labs(title = &quot;Time series line plot&quot;, subtitle = &quot;Gini coefficient over time&quot;) We can see that data on Gini coefficient for Australia, Canada, France and US are available since 1912, but for the rest data only becomes available late in the second half of the 20th century. While there are some differences across countries, the overall pattern can be summarized as follows: - income inequality (measured by Gini coefficient) was relatively high in the beginning of the 20th century and remained elevated until the 1930s-1940s, when it decreased substantially. - inequality remained relatively low for the next several decades, starting to pick up again at various points in the 1970s. - since then inequality has been overall increasing. This pattern is well known and documented. While various explanations for it have been proposed, a discussion is beyond the scope of this document. However, something that we can check in our data is whether the evolution of inequality in terms of Gini coefficients is similar to the evolution in terms of other measures. Unsurprisingly, it turns out that top income shares have followed a similar pattern: ggplot(panel, aes(x=Year, y=s10, col=Country)) + geom_line() + geom_point() + scale_color_brewer(palette = &quot;Dark2&quot;) + xlab(&quot;&quot;) + ylab(&quot;Top 10% income share&quot;) + labs(title = &quot;Time series line plot&quot;, subtitle = &quot;Top 10% income share over time&quot;) ggplot(panel, aes(x=Year, y=s1, col=Country)) + geom_line() + geom_point() + scale_color_brewer(palette = &quot;Dark2&quot;) + xlab(&quot;&quot;) + ylab(&quot;Top 1% income share&quot;) + labs(title = &quot;Time series line plot&quot;, subtitle = &quot;Top 1% income share over time&quot;) In summary, we observe a common pattern across a set of large developped economies, where income inequality has followed a U-shaped pattern over time for the last 100 years or so. At present, measures of inequality are elevated relative to the norm of the middle of the 20th century. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
